import torch
import numpy as np
from torch.utils.data import Dataset
from typing import Tuple

# Strategy 2: Eliminate Magic Values by defining named constants.
# These constants make the code's intent clear and easier to modify.
_IMAGE_SIZE = 64
_NUM_CHANNELS = 1
_INITIAL_BOX_SIZE = 2
_MAX_INITIAL_OFFSET = 20
_MIN_SHIFT_PER_FRAME = 2
_MAX_SHIFT_PER_FRAME = 5
_PIXEL_VALUE_MULTIPLIER = 0.02
_TRAIN_SPLIT_RATIO = 0.8
_NUM_CORNERS = 4


class BoxDataSet(Dataset):
    """
    A PyTorch Dataset that generates a synthetic sequence of images.

    Each sequence depicts a square that moves diagonally and grows in size over
    time. The pixel values within the square also increase linearly throughout
    the sequence. This dataset is intended for testing sequence-based
    forecasting models.

    Args:
        num_examples (int): The total number of example sequences to generate.
        in_seq_len (int): The number of frames in the input sequence.
        out_seq_len (int): The number of frames in the output (target) sequence.
        mode (str): The dataset mode, either "train" or "test". Determines
                    which subset of the data is used.
    """

    # Strategy 3: Improve Readability with clear type hinting.
    def __init__(self,
                 num_examples: int,
                 in_seq_len: int,
                 out_seq_len: int,
                 mode: str = "train"):

        if mode not in ("train", "test"):
            raise ValueError("Mode must be either 'train' or 'test'.")

        self.in_seq_len = in_seq_len
        self.out_seq_len = out_seq_len
        self.total_seq_len = in_seq_len + out_seq_len
        self.mode = mode

        # Strategy 1 & 4: SRP and Separation of Concerns.
        # The __init__ method now coordinates calls to focused helper methods.
        all_sequences = self._generate_all_sequences(num_examples)
        self._split_and_assign_data(all_sequences)

    # Strategy 1 & 4: This method has a Single Responsibility: generate all data.
    def _generate_all_sequences(self, num_examples: int) -> np.ndarray:
        """Generates the complete dataset of moving box sequences."""
        # Pre-allocate memory for all sequences.
        sequences = np.zeros(
            (num_examples, self.total_seq_len, _NUM_CHANNELS, _IMAGE_SIZE, _IMAGE_SIZE),
            dtype=np.float32
        )

        for i in range(num_examples):
            sequences[i] = self._create_single_sequence()

        # Strategy 3: Use descriptive variable names.
        # Original logic: Apply a multiplier to scale pixel values over time.
        time_step_multipliers = (np.arange(1, self.total_seq_len + 1) *
                                 _PIXEL_VALUE_MULTIPLIER)
        
        # Reshape for broadcasting: (1, total_seq_len, 1, 1, 1)
        # This allows NumPy to multiply each frame by its corresponding time step value.
        reshaped_multipliers = time_step_multipliers.reshape(1, self.total_seq_len, 1, 1, 1)

        # The sequences currently have 1s for the boxes. This scales them.
        return sequences * reshaped_multipliers

    # Strategy 1 & 4: This method's concern is generating just one sequence.
    def _create_single_sequence(self) -> np.ndarray:
        """Creates a single sequence of frames with a moving and growing box."""
        sequence = np.zeros(
            (self.total_seq_len, _NUM_CHANNELS, _IMAGE_SIZE, _IMAGE_SIZE),
            dtype=np.float32
        )

        # Per original code, an initial offset is chosen once per sequence.
        initial_x_offset = np.random.randint(0, _MAX_INITIAL_OFFSET + 1)
        initial_y_offset = np.random.randint(0, _MAX_INITIAL_OFFSET + 1)
        
        # A constant shift value is chosen once per sequence.
        start_corner = np.random.randint(0, _NUM_CORNERS)
        shift_per_frame = np.random.randint(_MIN_SHIFT_PER_FRAME, _MAX_SHIFT_PER_FRAME + 1)

        for time_step in range(self.total_seq_len):
            # Box size grows linearly with each time step.
            box_size = _INITIAL_BOX_SIZE + time_step
            
            # This logic now correctly matches the original code:
            # The total shift at time_step `t` is `t * shift_per_frame`.
            total_shift = time_step * shift_per_frame

            # Calculate box position based on start corner, initial offset, and total shift.
            if start_corner == 0:  # Top-left
                y_pos = initial_y_offset + total_shift
                x_pos = initial_x_offset + total_shift
            elif start_corner == 1:  # Top-right
                y_pos = initial_y_offset + total_shift
                x_pos = _IMAGE_SIZE - (initial_x_offset + total_shift) - box_size
            elif start_corner == 2:  # Bottom-left
                y_pos = _IMAGE_SIZE - (initial_y_offset + total_shift) - box_size
                x_pos = initial_x_offset + total_shift
            else:  # Bottom-right
                y_pos = _IMAGE_SIZE - (initial_y_offset + total_shift) - box_size
                x_pos = _IMAGE_SIZE - (initial_x_offset + total_shift) - box_size

            # Draw the box, clipping coordinates to stay within image bounds.
            y_start, y_end = max(0, y_pos), min(_IMAGE_SIZE, y_pos + box_size)
            x_start, x_end = max(0, x_pos), min(_IMAGE_SIZE, x_pos + box_size)
            
            sequence[time_step, 0, y_start:y_end, x_start:x_end] = 1.0
        
        return sequence

    # Strategy 1 & 5: This method's responsibility is to split data, clarifying the flow.
    def _split_and_assign_data(self, all_sequences: np.ndarray) -> None:
        """Splits the generated data into train/test and input/output sets."""
        num_examples = all_sequences.shape[0]
        split_index = int(num_examples * _TRAIN_SPLIT_RATIO)

        if self.mode == 'train':
            dataset_split = all_sequences[:split_index]
        else: # mode == 'test'
            dataset_split = all_sequences[split_index:]

        # Assign the final data subsets to be used by __getitem__
        self.input_sequences = dataset_split[:, :self.in_seq_len]
        self.output_sequences = dataset_split[:, self.in_seq_len:]

    def __len__(self) -> int:
        """Returns the number of examples in the current dataset mode (train/test)."""
        return self.input_sequences.shape[0]

    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Retrieves one example sequence at the specified index.

        Args:
            index (int): The index of the data point to retrieve.

        Returns:
            A tuple containing the input sequence tensor and the output
            (target) sequence tensor.
        """
        # Convert numpy arrays to float tensors for PyTorch model consumption.
        in_seq_tensor = torch.from_numpy(self.input_sequences[index]).float()
        out_seq_tensor = torch.from_numpy(self.output_sequences[index]).float()
        return in_seq_tensor, out_seq_tensor
