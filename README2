# LSTM Time Series Prediction Example

This example notebook shows how to use the Time Series Predictor in the PCM to
forecast both 2D (sine wave) and 3D data (missile trajectories).
import warnings
from math import cos, radians, sin
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import onnx
import onnxruntime as ort
import tensorflow as tf
from IPython.display import Image
from sklearn.model_selection import train_test_split

from cm_utilities.repo_path import REPO_PATH
from lm_ai_torch_data.inference.output_type import OutputType
from lm_ai_torch_training.configuration import TrainingConfiguration
from lm_ai_torch_training.optimizers.adam import AdamOptimizer
from prediction.configurations.time_series_predictor_configuration import (
    TimeSeriesPredictorConfiguration,
)
from prediction.data.example_datasets.noisy_sine_dataset import (
    NoisySineDataset,
    SplitType,
)
from prediction.data_types.keras_optimizer_type import KerasOptimizerType
from prediction.mlearn.lstm.architecture import LSTMArchitecture
from prediction.mlearn.lstm.lstm import LSTMPredictor
from prediction.mlearn.time_series_predictor import TimeSeriesPredictor

%load_ext autoreload
%autoreload 2
%matplotlib inline

warnings.filterwarnings("ignore")
## Introduction

One way to generate a many-to-many prediction is to use an LSTM sliding window
approach. An LSTM can be trained on an arbitrary input time-series size and
learn to predict the next value. To predict multiple time-steps in the future,
the predicted value can be used in the next input to the network.

The .infer() function takes a second parameter (`n_predictions`) which specifies
the number of sliding window predictions to make. For example, if you want to
predict the next 1000 time-steps, train a model that infers a single time-step
in the future and pass 1000 as the second argument to the infer function. The
image below helps to visualize this methodology.
images_path = (
    REPO_PATH / "examples/jupyter_notebooks/mlearn/time_series_predictor"
)
Image(filename=images_path / "LSTM Many to Many.png", width=500, height=500)
##  2D Sine Wave Example
### Generate 1D Mock Data (Noisy Sine Wave)

Here a noisy sine wave is generated consisting of 20,000 points which
will be used to generate the train and test data.
n_points: int = 20000
x = np.array([j / 40 for j in range(n_points)])
y = np.array(
    [0.5 * (sin(k) + 0.5 * (np.random.rand() - 0.5) + 0.95) for k in x]
)

plt.figure(figsize=(10, 5))
plt.plot(x, y)
plt.legend(["Sin(x) + noise"])
plt.xlim([4, 40])
### Define Helper Functions
def to_sequences(
    data: np.ndarray, in_seq_len: int, out_seq_len: int
) -> tuple[np.ndarray, np.ndarray]:
    """Converts an input dataset to input and output sequences.

    Args:
        data: The dataset to convert to input and output sequences.
        in_seq_len: The length of an input sequence of data.
        out_seq_len: The length of an output sequence of data.

    Returns:
        The dataset converted to input and output sequences.
    """
    x: list[np.ndarray] = []
    y: list[np.ndarray] = []
    for index in range(len(data) - in_seq_len - out_seq_len):
        x.append(data[index : index + in_seq_len])
        y.append(data[index + in_seq_len : index + in_seq_len + out_seq_len])

    return np.expand_dims(np.array(x), 2), np.expand_dims(np.array(y), 2)
### Preprocess the Data

The noisy sine wave will be broken up into sliding window sequences of 101
points, where 100 points will be used as the input sequence and the model will
predict 1 point into the future. Because the sine wave only has a singular
y-value for each x timestep, `NUM_FEATURES` will be set to one (1).

Following the preprocessing of the data, the data shapes should follow:
* Input Data: `(number_examples, input_sequence_length, number_of_features)`
* Output Data: `(number_examples, output_sequence_length, number_of_features)`
IN_SEQ_LEN: int = 100
OUT_SEQ_LEN: int = 1

x, y = to_sequences(y, IN_SEQ_LEN, OUT_SEQ_LEN)
x_train, x_test, y_train, y_test = train_test_split(
    x, y, train_size=0.95, random_state=42
)

print(f"X Shape: {x.shape}")
print(f"y Shape: {y.shape}")
print(f"x_train Shape: {x_train.shape}")
print(f"y_train Shape: {y_train.shape}")
print(f"x_test Shape: {x_test.shape}")
print(f"y_test Shape: {y_test.shape}")
### Visualize Training Inputs and Outputs

Here are 2 examples of input/output pairs, one at index 0 and the next at index
50 in the training data. The input to the model will be 100 sequential points
and the ground truth will be the next time-step.
samples: list[int] = [0, 50]
fig, axs = plt.subplots(len(samples), figsize=(10, 10))

# Generate plot indices for x_train[sample] and y_train[sample].
x1: list[int] = [i for i in range(len(x_train[0]))]
x2: list[int] = [i + x1[-1] for i in range(len(y_train[0]))]  # Start at 99

for i, sample in enumerate(samples):
    axs[i].plot(x1, x_train[sample])
    axs[i].plot(x2, y_train[sample], "rx")
    axs[i].legend(["X", "y"])
### Custom Loss Function

Here a custom loss function is created to dissuade the network from inferring
negative values. For example, if the sine wave generated was noisy elevation
data recorded from a drone, the network should be penalized for inferring
negative values. Similarly, a custom loss function can be created that penalizes
inferred values based on certain laws of physics.

**Note**: Custom loss functions must use tensorflow functions to perform
operations on the ground truth and predicted values.
def custom_loss_no_negatives(y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:
    """Defines a custom loss function that penalizes negative predictions.

    Args:
        y_true: The true values in the dataset.
        y_pred: The predicted values from the model.

    Returns:
        The loss for this set of true and predicted values.
    """
    neg_pred: tf.Tensor = 2000 * tf.cast(y_pred > 0, y_pred.dtype)
    pos_pred: tf.Tensor = 1 * tf.cast(y_pred <= 0, y_pred.dtype)

    # Define a mask to penalize negative predictions.
    penalizer: tf.Tensor = neg_pred + pos_pred

    squared_difference: tf.Tensor = tf.square(y_true - y_pred)
    squared_difference_penalty: tf.Tensor = squared_difference * penalizer

    return tf.reduce_mean(squared_difference_penalty, axis=-1)
### Define and Train the Deterministic Model

A hyperparameter object is created and populated with the model parameters. The 
deterministic model will produce the same prediction for each inference.
IN_SEQ_LEN = 100
OUT_SEQ_LEN = 1
NUM_FEATURES = 1

hidden_units_1: int = 5
hidden_units_2: int = 10

deterministic_predictor: TimeSeriesPredictor = TimeSeriesPredictor(
    configuration=TimeSeriesPredictorConfiguration(
        input_sequence_length=IN_SEQ_LEN,
        output_sequence_length=OUT_SEQ_LEN,
        num_features=NUM_FEATURES,
        num_epochs=10,
        loss=custom_loss_no_negatives,
        hidden_units_1=hidden_units_1,
        hidden_units_2=hidden_units_2,
        deterministic=True,
    ),
)
checkpoints_path: Path = Path("checkpoints")
if not checkpoints_path.exists():
    checkpoints_path.mkdir(parents=True)

print("\nTraining the Deterministic Predictor\n")
d_history = deterministic_predictor.fit(x_train, y_train)
### Visualize the Deterministic Training Metrics

The sine function is relatively simple, therefore, the model converges in a few
epochs.
plt.plot(d_history.history["loss"])
plt.plot(d_history.history["val_loss"])
plt.xlabel("Epoch")
plt.ylabel("Loss Value")
plt.title("Deterministic Model Metrics")
plt.legend(["Training", "Validation"])
plt.show()
### Define and Train the Stochastic Model

A hyperparameter object is created and populated with the model parameters. For
the stochastic (unique) model, the optimizer is updated to the SGD optimizer as
it performs far better than the ADAM optimizer with the underlying VED model.
The stochastic model will be non-deterministic and can be used to generate
multiple possible futures.
IN_SEQ_LEN = 100
OUT_SEQ_LEN = 1
NUM_FEATURES = 1

hidden_units_1 = 16
hidden_units_2 = 32

stochastic_predictor: TimeSeriesPredictor = TimeSeriesPredictor(
    configuration=TimeSeriesPredictorConfiguration(
        input_sequence_length=IN_SEQ_LEN,
        output_sequence_length=OUT_SEQ_LEN,
        num_features=NUM_FEATURES,
        num_epochs=10,
        optimizer=KerasOptimizerType.RMS_PROP,
        hidden_units_1=hidden_units_1,
        hidden_units_2=hidden_units_2,
        deterministic=False,
    ),
)
print("\nTraining the Stochastic Predictor\n")
s_history = stochastic_predictor.fit(x_train, y_train)
### Visualize the Stochastic Training Metrics

The sine function is relatively simple, but the model struggles as seen by the
flat nature of the loss curves. Early-stopping kicked in even before the 10
epochs were completed.
plt.plot(s_history.history["loss"])
plt.plot(s_history.history["val_mean_absolute_error"])
plt.xlabel("Epoch")
plt.ylabel("Loss Value")
plt.title("Stochastic Model Metrics")
plt.legend(["Training", "Validation"])
plt.show()
### Define and Train the LSTM Model

As one last test, a standard LSTM prediction model will be trained on the sine
wave dataset. This model is torch based, thus a torch dataset class has been
created called the `NoisySineDataset`.
IN_SEQ_LEN = 100
OUT_SEQ_LEN = 1
NUM_FEATURES = 1

train_dataset = NoisySineDataset(
    sequence_length=IN_SEQ_LEN, split=SplitType.TRAIN
)
valid_dataset = NoisySineDataset(
    sequence_length=IN_SEQ_LEN, split=SplitType.VALIDATION
)

print("Training Dataset Metrics")
print(f"---> Length: {len(train_dataset)}")
print(f"---> Input Sequence Shape: {train_dataset[0][0].shape}")
print(f"---> Output Sequence Shape: {train_dataset[0][1].shape}")

print("Validation Dataset Metrics")
print(f"---> Length: {len(valid_dataset)}")
print(f"---> Input Sequence Shape: {valid_dataset[0][0].shape}")
print(f"---> Output Sequence Shape: {valid_dataset[0][1].shape}")
Configure the model and training configuration, create the LSTM predictor, and
run model training. 
lstm_architecture = LSTMArchitecture(
    hidden_dim=256,
    output_dim=1,
    n_layers=1,
    batch_size=8,
    sequence_length=IN_SEQ_LEN,
)

training_configuration = TrainingConfiguration(
    optimizer=AdamOptimizer(betas=(0.5, 0.999)),
    batch_size=8,
    n_epochs=10,
)

lstm_predictor = LSTMPredictor(
    architecture=lstm_architecture,
    training_configuration=training_configuration,
)
print("\nTraining the LSTM Predictor\n")
lstm_history = lstm_predictor.fit(
    train_dataset=train_dataset,
    val_dataset=valid_dataset,
)
### Visualize the Training Metrics

This model seems to perform similarly to the deterministic model shown above.
training_loss = lstm_history["loss"][:-1]
validation_loss = lstm_history["validation_loss"][:-1]
epochs = list(range(len(training_loss)))

plt.figure(figsize=(10, 5))
plt.plot(epochs, training_loss)
plt.plot(epochs, validation_loss)
plt.title("LSTM Model Metrics")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend(["Training", "Validation"])
plt.show()
### Run Inference
#### LSTM Model

The LSTM model will be used going forward to infer on the test dataset and
visualize performance on an unseen dataset.
test_dataset = NoisySineDataset(
    sequence_length=IN_SEQ_LEN, split=SplitType.TEST
)
print("Test Dataset Metrics")
print(f"---> Length: {len(test_dataset)}")
print(f"---> Input Sequence Shape: {test_dataset[0][0].shape}")
print(f"---> Output Sequence Shape: {test_dataset[0][1].shape}")
inference_results = lstm_predictor.infer(
    test_dataset, output_type=OutputType.NUMPY
)

inputs: np.ndarray = np.array(inference_results[0])
predictions: np.ndarray = np.array(inference_results[1])

print(f"Inputs Shape: {inputs.shape}")
print(f"Predictions Shape: {predictions.shape}")
Below, three different input sequences and predictions from the test dataset
will be visualized. Overall, the LSTM model seems to perform quite well.
samples = [0, 50, 100]
x1 = [i for i in range(len(inputs[1]))]
x2 = [i + x1[-1] for i in range(len(predictions[1]))]
fig, axs = plt.subplots(len(samples), figsize=(10, 10))
for i, sample in enumerate(samples):
    axs[i].plot(x1, inputs[sample], "b")
    axs[i].plot(x2, predictions[sample], "rx")
    axs[i].set_title(f"Sample {sample}")
    axs[i].set_xlabel("Timestep")
    axs[i].set_ylabel("Value")
    axs[i].legend(["Input", "Prediction"])

plt.tight_layout()
plt.show()
#### Deterministic Model
samples = [0, 50]
last_time_step: int = x1[-1]
num_preds: int = 100
num_trajs: int = 5

y_preds = []
for _ in range(num_trajs):
    y_preds.append(
        deterministic_predictor.infer(x_test, num_predictions=num_preds)
    )
fig, axs = plt.subplots(len(samples), figsize=(10, 10))
x3: list[int] = [i + last_time_step for i in range(num_preds * len(y_train[0]))]
for j in range(num_trajs):
    for i, sample in enumerate(samples):
        axs[i].plot(x1, x_test[sample], "b")
        axs[i].plot(x3, y_preds[j][sample], "--")
        axs[i].set_title(f"Sample {sample}")
        axs[i].set_xlabel("Timestep")
        axs[i].set_ylabel("Value")
        axs[i].legend(["Input", "Prediction"])
#### Stochastic Model
samples = [10, 60]
last_time_step = x1[-1]
num_preds = 100
num_trajs = 5

y_preds = []
for _ in range(num_trajs):
    y_preds.append(
        stochastic_predictor.infer(x_test, num_predictions=num_preds)
    )
fig, axs = plt.subplots(len(samples), figsize=(10, 10))
x3 = [i + last_time_step for i in range(num_preds * len(y_train[0]))]
labels: list[str] = ["Input"] + [f"Prediction {i}" for i in range(num_trajs)]
for i, sample in enumerate(samples):
    axs[i].plot(x1, x_test[sample], "b")
    for j in range(num_trajs):
        axs[i].plot(x3, y_preds[j][sample], "--")
    axs[i].set_title(f"Sample {sample}")
    axs[i].set_xlabel("Timestep")
    axs[i].set_ylabel("Value")
    axs[i].legend(labels)
As the plots above show, the stochastic model performs quite poorly in
comparison o the deterministic model shown above. Thus, the deterministic model
will be used moving forward in the notebook.
## 3D Trajectory Example

Now this notebook will expand by demonstrating the use of the Time Series
Predictor on 3D trajectory data and prediction.
### Generate Mock Trajectory Data

Each trajectory will be 1/2 wavelength of a shifted cosine function originating
from the origin and will consist of 400 points.
NUM_SIGNALS: int = 2000
NUM_PTS_PER_SIGNAL: int = 400

trajectory_list: list[np.ndarray] = []
for _ in range(NUM_SIGNALS):
    radius: float = np.random.uniform(0.4, 1.0)

    rand_angle: float = radians(np.random.randint(1, 359))
    rand_width: float = np.random.uniform(0.5, 1.0)
    rand_height: float = np.random.uniform(0.5, 1.0)

    x_end: float = round(radius * np.cos(rand_angle), 3)
    y_end: float = round(radius * np.sin(rand_angle), 3)
    if x_end == 0:
        x_end = round(radius * np.cos(1), 3)

    m: float = y_end / x_end
    x = np.linspace(0, x_end, NUM_PTS_PER_SIGNAL)
    y = x * m
    offset: float = 3 * np.pi / 2
    z: list[float] = [
        (rand_height * (cos(np.pi * np.abs(k) / np.abs(x_end) + offset)))
        for k in x
    ]

    x_: np.ndarray = np.expand_dims(x, axis=1)
    y_: np.ndarray = np.expand_dims(y, axis=1)
    z_: np.ndarray = np.expand_dims(z, axis=1)
    trajectory: np.ndarray = np.squeeze(np.concatenate((x_, y_, z_), axis=1))

    trajectory_list.append(trajectory)

trajectories: np.ndarray = np.array(trajectory_list)
print(f"Trajectories Shape: {trajectories.shape}")
Below, the first 50 trajectories are plotted.
plt.close("all")
fig = plt.figure(figsize=(12, 12))
ax = plt.axes(projection="3d")
for _ in range(50):
    r: int = np.random.randint(0, NUM_SIGNALS - 1)
    ax.plot(trajectories[r, :, 0], trajectories[r, :, 1], trajectories[r, :, 2])

ax.set_title("Mock Trajectories")
ax.set_xlabel("X")
ax.set_ylabel("Y")
ax.set_zlabel("Z")
plt.tight_layout()
<h3>Preprocess Helper Functions</h3>
def data_to_sequences(
    data: np.ndarray, in_seq_len: int, out_seq_len: int
) -> tuple[np.ndarray, np.ndarray]:
    """Converts an input dataset to input and output sequences.

    Args:
        data: The dataset to convert to input and output sequences.
        in_seq_len: The length of an input sequence of data.
        out_seq_len: The length of an output sequence of data.

    Returns:
        The dataset converted to input and output sequences.
    """
    x = data[:, :in_seq_len, :]
    y = data[:, in_seq_len - 1 : -1, :]
    return np.squeeze(x), np.squeeze(y)
### Preprocess the Data

In this case, the input sequence length is 300 but the output lengths will vary
from 1 - 50, just as was done with the 2D sine wave data. Contrary to the 2D
sine data, trajectory data is 3D in nature and three (3) values (x, y, and z)
will be predicted for each timestep, thus `NUM_FEATURES`` will be set to 3.

After preprocessing the data, the data shapes should follow:
* Input Shape: (number examples, input sequence length, number of features)
* Output Shape: (number examples, output sequence length, number of features)
IN_SEQ_LEN = 300
OUT_SEQ_LEN = NUM_PTS_PER_SIGNAL - IN_SEQ_LEN
NUM_FEATURES = 3  # 3D coordinates.

train, test = train_test_split(trajectories, train_size=0.90)
print(f"Train Shape: {train.shape}")
print(f"Test Shape: {test.shape}")

x_train, y_train = data_to_sequences(train, IN_SEQ_LEN, OUT_SEQ_LEN)
x_test, y_test = data_to_sequences(test, IN_SEQ_LEN, OUT_SEQ_LEN)
print(f"X Train Shape: {x_train.shape}")
print(f"X Test Shape: {x_test.shape}")
print(f"Y Train Shape: {y_train.shape}")
print(f"Y Test Shape: {y_test.shape}")
### Visualize Training Inputs and Outputs

Below are a few examples of the input/output sequences for each of the models.
Several trajectories are plotted in various colors, one for each of the defined
output sequences lengths. Each of the defined output sequence lengths is plotted
as well which can be seen by the varying lengths of the red lines at the end of
the trajectories.
fig = plt.figure(figsize=(12, 12))
ax = plt.axes(projection="3d")

for i in range(10):
    ax.plot3D(x_train[i, :, 0], x_train[i, :, 1], x_train[i, :, 2], "gray")
    ax.plot3D(y_train[i, :, 0], y_train[i, :, 1], y_train[i, :, 2], "r")

ax.legend(["Inputs", "Outputs"])
ax.set_xlabel("X")
ax.set_ylabel("Y")
ax.set_zlabel("Z")
### Define and Train a Model
hidden_units_1 = 16
hidden_units_2 = 100

predictor: TimeSeriesPredictor = TimeSeriesPredictor(
    configuration=TimeSeriesPredictorConfiguration(
        input_sequence_length=IN_SEQ_LEN,
        output_sequence_length=OUT_SEQ_LEN,
        num_features=NUM_FEATURES,
        num_epochs=75,
        checkpoint="checkpoints/3D_Mock",
        loss=custom_loss_no_negatives,
        hidden_units_1=hidden_units_1,
        hidden_units_2=hidden_units_2,
        deterministic=True,
    ),
)

print(f"Model Architecture:\n{predictor.model.summary()}")
checkpoints_path = Path("checkpoints")
if not checkpoints_path.exists():
    checkpoints_path.mkdir(parents=True)

history = predictor.fit(
    x_train,
    y_train,
    additional_data=(x_test, y_test),
)
### Visualize the Training Metrics
plt.figure()
plt.plot(history.history["loss"])
plt.plot(history.history["val_loss"])
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend(["Training", "Validation"])
plt.show()
### Load the Best Model Weights

By default, the model weights with the lowest loss/validation loss will be
saved in the checkpoint. When using a validation set, the weights that minimize
the validation loss can be loaded to avoid overfitting.
predictor.load("checkpoints/3D_Mock")
### Trajectory Inference Visualization
fig = plt.figure(figsize=(15, 15))
ax = plt.axes(projection="3d")

samples = [1, 5, 7]
y_pred = predictor.infer(x_test[samples])
for i, sample in enumerate(samples):
    ax.plot(
        x_test[sample][:, 0], x_test[sample][:, 1], x_test[sample][:, 2], "b"
    )
    ax.plot(
        y_test[sample][:, 0], y_test[sample][:, 1], y_test[sample][:, 2], "g"
    )
    ax.plot(y_pred[i][:, 0], y_pred[i][:, 1], y_pred[i][:, 2], "r--")

ax.set_xlabel("X")
ax.set_ylabel("Y")
ax.set_zlabel("Z")
ax.legend(["Input", "Ground Truth", "Prediction"])
### Open Neural Network Exchange (ONNX)

Many models in the CMs have the ability to export to a common neural network
file format called ONNX. This next section will demonstrate how to utilize this
functionality to save and load models.
#### Save Model to ONNX

On top of being able to automatically save and restore checkpoints, the Time
Series Predictor is able to save the trained model to the ONNX export format.
The cells below will save the model to ONNX, reload the model, and run an
inference in order to demonstrate the workflow.
model_path: Path = (
    REPO_PATH / "examples/jupyter_notebooks/mlearn/time_series_predictor"
)

predictor.to_onnx(model_path)
#### Load the Saved ONNX Model
lstm_path: Path = model_path / "lstm.onnx"
onnx_model = onnx.load(lstm_path).SerializeToString()

try:
    onnx.checker.check_model(onnx_model)
except onnx.checker.ValidationError as e:
    print(f"The model is invalid: {e}")
else:
    print("The model is valid!")

sess_options = ort.SessionOptions()
sess_options.graph_optimization_level = (
    ort.GraphOptimizationLevel.ORT_DISABLE_ALL
)
session = ort.InferenceSession(lstm_path, sess_options)
#### Perform Inference on the ONNX Model
def call(sess: ort.InferenceSession, data: np.ndarray) -> np.ndarray:
    """Calls an ONNX session to perform inference.

    Args:
        sess: The onnx runtime session to use for inference.
        data: The data to inference on the model with.

    Returns:
        The predictions made by the onnx model.
    """
    x = np.array(data, dtype=np.float32)
    input_dict: dict[str, np.ndarray] = {"input": x}

    output_dict: dict[int, np.ndarray] = sess.run(None, input_dict)
    y_pred: np.ndarray = np.array(output_dict[0])

    return y_pred
Using the ONNX model, four (4) samples will be used to perform inference and the
inference results are shown below.
batch_size: int = 4
print(f"Input Shape: {x_test[:batch_size].shape}")

y_pred = call(session, x_test[:batch_size])
print(f"Output Shape: {y_pred.shape}")
plt.close("all")
fig = plt.figure(figsize=(15, 15))
ax = plt.axes(projection="3d")

samples = [0, 1, 2, 3]

for sample in samples:
    ax.plot(
        x_test[sample][:, 0], x_test[sample][:, 1], x_test[sample][:, 2], "b"
    )
    ax.plot(
        y_test[sample][:, 0], y_test[sample][:, 1], y_test[sample][:, 2], "g"
    )
    ax.plot(
        y_pred[sample][:, 0], y_pred[sample][:, 1], y_pred[sample][:, 2], "r--"
    )

ax.set_xlabel("X")
ax.set_ylabel("Y")
ax.set_zlabel("Z")
ax.legend(["Input", "Ground Truth", "Prediction"])
## Conclusion

This notebook demonstrated how to use the Time Series Predictor to train on and
forecast both 2D and 3D data, as well as a standard LSTM model. Along with this,
the ONNX utilities in the Time Series Predictor were shown in order to
demonstrate how to save a model to the ONNX format, load a model in the ONNX
format, and run an inference using the loaded ONNX model.

The next question to ask is, which output sequence length will be best for my
problem? In the "Output Size Demo" notebook
[here](https://gitlab.us.lmco.com/cto-ai/cognitive-modules/prediction/prediction-core/-/blob/main/examples/jupyter_notebooks/mlearn/time_series_predictor/lstm_time_series_predictor_output_size_example.ipynb?ref_type=heads),
further exploration is conducted on how different
output sequence lengths affect model performance.
