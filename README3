F-35 anomaly detection
from plotly.subplots import make_subplots  # add near your imports at the top


def fr_feature_plot(
    df: pd.DataFrame,
    selected_features: list[str],
    mode: str = "2D",
) -> go.Figure:
    """
    Visualize Failure Rate (FR) as a function of up to 2 features.

    - 2D mode:
        * If 1 feature:
            - Bar chart of average FR by binned (numeric) or categorical values.
        * If 2 features:
            - Two side-by-side bar charts (one per feature).
    - 3D mode:
        * Requires exactly 2 features.
        * 3D scatter: x = feature1, y = feature2, z = FR (per run),
          colored by FR.
    """
    fig = go.Figure()

    if "FR" not in df.columns:
        fig.update_layout(
            title="FR not available",
            height=250,
            margin=dict(l=10, r=10, t=40, b=40),
        )
        return fig

    FR = df["FR"].astype(float)

    def is_numeric(series: pd.Series) -> bool:
        return np.issubdtype(series.dtype, np.number)

    # No features selected
    if not selected_features:
        fig.update_layout(
            title="Select 1 or 2 features to view their relationship to FR",
            height=200,
            margin=dict(l=10, r=10, t=40, b=40),
        )
        return fig

    # ------------------------ 3D MODE ------------------------
    if mode == "3D":
        if len(selected_features) != 2:
            fig.update_layout(
                title="3D FR plot requires exactly 2 selected features",
                height=220,
                margin=dict(l=10, r=10, t=40, b=40),
            )
            return fig

        f1, f2 = selected_features
        if f1 not in df.columns or f2 not in df.columns:
            fig.update_layout(
                title="Selected features not in DataFrame",
                height=220,
                margin=dict(l=10, r=10, t=40, b=40),
            )
            return fig

        s1 = df[f1]
        s2 = df[f2]

        # Encode categoricals as codes so we can place them on axes
        if not is_numeric(s1):
            s1_num = s1.astype("category").cat.codes.astype(float)
        else:
            s1_num = s1.astype(float)

        if not is_numeric(s2):
            s2_num = s2.astype("category").cat.codes.astype(float)
        else:
            s2_num = s2.astype(float)

        hovertext = [
            f"Test Run ID: {trid}<br>{f1}: {v1}<br>{f2}: {v2}<br>FR: {fr:.3f}"
            for trid, v1, v2, fr in zip(
                df.get("Test_Run_ID", df.index),
                s1,
                s2,
                FR,
            )
        ]

        fig.add_trace(
            go.Scatter3d(
                x=s1_num,
                y=s2_num,
                z=FR,
                mode="markers",
                marker=dict(
                    size=4,
                    color=FR,
                    colorscale="RdYlGn_r",  # low FR = green, high FR = red
                    colorbar=dict(title="FR"),
                ),
                hovertext=hovertext,
                hoverinfo="text",
            )
        )
        fig.update_layout(
            title=f"FR vs {f1} and {f2} (3D)",
            scene=dict(
                xaxis_title=f1,
                yaxis_title=f2,
                zaxis_title="FR",
            ),
            height=600,
            margin=dict(l=10, r=10, t=40, b=10),
        )
        return fig

    # ------------------------ 2D MODE ------------------------
    # Helper for a single feature: average FR by bin/category
    def avg_fr_by_feature(feature: str) -> tuple[list[str], np.ndarray]:
        s = df[feature]
        if is_numeric(s):
            try:
                # Bin into up to 10 quantile bins
                q = pd.qcut(
                    s.rank(method="first"),
                    10,
                    duplicates="drop",
                )
                grouped = df.assign(_bin=q).groupby("_bin")["FR"].mean()
                x_labels = [str(idx) for idx in grouped.index]
                y_vals = grouped.values
            except Exception:
                # Fallback: treat raw values (may be messy)
                grouped = df.groupby(feature)["FR"].mean()
                x_labels = [str(idx) for idx in grouped.index]
                y_vals = grouped.values
        else:
            grouped = df.groupby(feature)["FR"].mean()
            # Show top 15 by frequency / mean FR
            counts = df[feature].value_counts()
            top_vals = counts.index[:15]
            grouped = grouped.loc[grouped.index.intersection(top_vals)]
            grouped = grouped.sort_values(ascending=False)
            x_labels = [str(idx) for idx in grouped.index]
            y_vals = grouped.values

        return x_labels, y_vals

    # 2D, 1 feature
    if len(selected_features) == 1:
        f = selected_features[0]
        if f not in df.columns:
            fig.update_layout(
                title="Selected feature not in DataFrame",
                height=220,
                margin=dict(l=10, r=10, t=40, b=40),
            )
            return fig

        x, y = avg_fr_by_feature(f)
        fig.add_trace(go.Bar(x=x, y=y))
        fig.update_layout(
            title=f"Average FR by {f}",
            xaxis_title=f,
            yaxis_title="Average FR",
            height=400,
            margin=dict(l=10, r=10, t=40, b=80),
        )
        return fig

    # 2D, 2 features => two side-by-side bar charts
    f1, f2 = selected_features[:2]
    if f1 not in df.columns or f2 not in df.columns:
        fig.update_layout(
            title="Selected features not in DataFrame",
            height=220,
            margin=dict(l=10, r=10, t=40, b=40),
        )
        return fig

    x1, y1 = avg_fr_by_feature(f1)
    x2, y2 = avg_fr_by_feature(f2)

    fig = make_subplots(
        rows=1,
        cols=2,
        subplot_titles=[f"Average FR by {f1}", f"Average FR by {f2}"],
    )

    fig.add_trace(go.Bar(x=x1, y=y1, name=f1), row=1, col=1)
    fig.add_trace(go.Bar(x=x2, y=y2, name=f2), row=1, col=2)

    fig.update_xaxes(title_text=f1, row=1, col=1)
    fig.update_yaxes(title_text="Average FR", row=1, col=1)
    fig.update_xaxes(title_text=f2, row=1, col=2)
    fig.update_yaxes(title_text="Average FR", row=1, col=2)

    fig.update_layout(
        title="Average FR by selected features",
        showlegend=False,
        height=450,
        margin=dict(l=10, r=10, t=40, b=80),
    )
    return fig





=========================================================================================================================================================================
=========================================================================================================================================================================

def _render_table_and_plot(
    df: pd.DataFrame,
    PCs: np.ndarray,
    scores01: np.ndarray,
    raw_scores: np.ndarray,
    method_label: str,
    key_prefix: str,
    pca,                  # fitted PCA object (for loadings/arrows)
    pca_arrow_features: list[str],  # user-selected PCA features for arrows
):
    """
    Renders, for a given anomaly scoring method:

      1) Top anomalies table with row selection
      2) PCA scatter plot (3D) with optional highlight and PCA driver arrows
      3) Secondary tab set:
           - Storyboard:
               * Feature-wise FR viewer (2D/3D)
               * 'Why this run?' bar chart for selected run
           - Anomaly Influence Network:
               * Feature co-movement network among top-K features
    """
    df = df.copy()
    df["anomaly_score"] = scores01
    df["raw_anomaly_score"] = raw_scores

    st.markdown(f"### {method_label}")

    # -------------------------------------------------------------------------
    # Top anomalies table & selection
    # -------------------------------------------------------------------------
    highlight_pos: int | None = None
    show_top = st.session_state.get("show_top", 10)

    if show_top > 0:
        cols_keep = [
            "Test_Run_ID",
            "FR",
            "Num_Tests",
            "total_init_time",
            "anomaly_score",
            "raw_anomaly_score",
            "Simulation_Host",
            "Simulation_Node",
            "Capability",
            "Script_File",
            "V",
            "s_number",
            "Build",
        ]
        cols_keep = [c for c in cols_keep if c in df.columns]

        top = df.sort_values("anomaly_score", ascending=False).head(show_top)

        st.markdown("**Top anomalies**")
        editable = top[cols_keep].copy()
        editable.insert(0, "Select", False)

        edited = st.data_editor(
            editable,
            use_container_width=True,
            num_rows="fixed",
            disabled={c: True for c in editable.columns if c != "Select"},
            key=f"{key_prefix}-table",
        )

        # Map selected row back to original df index
        selected_original_idxs = edited.index[edited["Select"]].tolist()
        if selected_original_idxs:
            pos = df.index.get_indexer([selected_original_idxs[0]])
            if len(pos) and pos[0] != -1:
                highlight_pos = int(pos[0])

    # -------------------------------------------------------------------------
    # PCA plot (full width) with optional driver arrows
    # -------------------------------------------------------------------------
    label_choice = st.session_state.get("label_choice", "Failure Rate")

    fig = plot_for_df(
        df,
        PCs,
        label_choice=label_choice,
        highlight_pos=highlight_pos,
    )

    show_biplot = st.session_state.get("show_biplot", True)
    if show_biplot and PCs.shape[1] >= 2 and pca is not None:
        from typing import cast
        default_arrow_feats = cast(list[str], globals().get("PCA_FEATURES", []))
        arrow_feats = st.session_state.get("pca_arrow_features", pca_arrow_features) or default_arrow_feats

        show_global_pca_arrows = st.session_state.get("show_global_pca_arrows", True)
        show_low_fr_arrows = st.session_state.get("show_low_fr_arrows", True)
        show_high_fr_arrows = st.session_state.get("show_high_fr_arrows", True)

        # Global arrows from origin
        if show_global_pca_arrows:
            try:
                add_pca_loadings_3d(fig, pca, arrow_feats, scale=2.0)
            except Exception:
                pass

        # Segment-anchored arrows near Low-FR and High-FR bands
        try:
            seg = make_fr_segments(df)  # "Low FR" / "High FR"

            if seg is not None:
                if show_low_fr_arrows:
                    low_mask = (seg == "Low FR").values
                    if np.any(low_mask):
                        low_anchor = PCs[low_mask].mean(axis=0)
                        add_biplot_arrows_at_anchor_3d(
                            fig,
                            pca,
                            arrow_feats,
                            low_anchor,
                            scale=1.2,
                            color="green",
                            name_prefix="Low FR ",
                            showlegend=False,
                        )

                if show_high_fr_arrows:
                    high_mask = (seg == "High FR").values
                    if np.any(high_mask):
                        high_anchor = PCs[high_mask].mean(axis=0)
                        add_biplot_arrows_at_anchor_3d(
                            fig,
                            pca,
                            arrow_feats,
                            high_anchor,
                            scale=1.2,
                            color="red",
                            name_prefix="High FR ",
                            showlegend=False,
                        )
        except Exception:
            pass

    st.plotly_chart(fig, use_container_width=True, key=f"{key_prefix}-plot")

    # -------------------------------------------------------------------------
    # Secondary tabs: Storyboard | Anomaly Influence Network
    # -------------------------------------------------------------------------
    sub_story, sub_net = st.tabs(["Storyboard", "Anomaly Influence Network"])

    # --- Storyboard tab ------------------------------------------------------
    with sub_story:
        st.session_state["active_secondary"] = "Storyboard"

        show_segment_compare = st.session_state.get("show_segment_compare", True)
        show_selection_why = st.session_state.get("show_selection_why", True)

        # ---------- NEW Segment Comparison: Feature-wise FR viewer ----------
        if show_segment_compare:
            st.markdown("#### Feature-wise Failure Rate (FR) Viewer")

            # Limit feature choices to those in FEATURES_FOR_ANALYSIS and in df
            available_feats = [
                f for f in globals().get("FEATURES_FOR_ANALYSIS", [])
                if f in df.columns
            ]
            st.caption("Select up to 2 features to see how they relate to FR.")

            selected_features = st.multiselect(
                "Features",
                options=available_feats,
                default=available_feats[:1] if available_feats else [],
                max_selections=2,
                key=f"{key_prefix}-frfeat-select",
            )

            dim_choice = st.radio(
                "Plot dimension",
                options=["2D", "3D"],
                index=0,
                horizontal=True,
                key=f"{key_prefix}-frfeat-dim",
            )

            seg_fig = fr_feature_plot(
                df=df,
                selected_features=selected_features,
                mode=dim_choice,
            )
            st.plotly_chart(seg_fig, use_container_width=True, key=f"{key_prefix}-segplot")

        # Per-selection “Why this run?”
        if show_selection_why and highlight_pos is not None:
            st.markdown("#### Why this run?")
            st.plotly_chart(
                per_point_contribution_bar(df, highlight_pos),
                use_container_width=True,
                key=f"{key_prefix}-whybar",
            )

    # --- Anomaly Influence Network tab --------------------------------------
    with sub_net:
        st.session_state["active_secondary"] = "Anomaly Influence Network"

        show_influence_network = st.session_state.get("show_influence_network", True)
        if show_influence_network:
            subset = st.session_state.get("influence_subset", "Anomalous (top 5%)")
            top_k = st.session_state.get("influence_topk", 10)
            edge_thresh = st.session_state.get("influence_edge_thresh", 0.40)
            corr_method = st.session_state.get("influence_corr_method", "pearson")

            net_fig = anomaly_influence_network_figure(
                df,
                scores01,
                subset=subset,
                q=0.95,
                top_k=top_k,
                edge_thresh=edge_thresh,
                corr_method=corr_method,
            )
            st.plotly_chart(
                net_fig,
                use_container_width=True,
                key=f"{key_prefix}-influence",
            )


=========================================================================================================================================================================
=========================================================================================================================================================================



=========================================================================================================================================================================
=========================================================================================================================================================================

=========================================================================================================================================================================
=========================================================================================================================================================================
kinematic-classifier

# conftest.py (alternative)
import pytest, shutil
from pathlib import Path

@pytest.fixture()
def repo_data_files_with_fakes(tmp_path, monkeypatch):
    root = Path(__file__).resolve().parents[1]
    fake_src = root / "data" / "fake_data_files"
    real_dst = root / "my_pkg" / "data" / "data_files"

    backups = []
    real_dst.mkdir(parents=True, exist_ok=True)

    # backup any existing files, then copy fakes
    for f in real_dst.glob("*"):
        b = tmp_path / f.name
        shutil.copy2(f, b)
        backups.append((f, b))
    for f in fake_src.iterdir():
        if f.is_file():
            shutil.copy2(f, real_dst / f.name)

    yield real_dst  # tests run with fakes in place

    # restore previous contents
    for f in real_dst.glob("*"):
        f.unlink()
    for dst, backup in backups:
        shutil.copy2(backup, dst)

=========================================================================================================================================================================
=========================================================================================================================================================================




=========================================================================================================================================================================
=========================================================================================================================================================================
PG-35: Susceptibility Modeling

import pandas as pd
import numpy as np

def engineer_flight_dynamics_features(df):
    """
    Engineers aerospace-specific features for Drone Tag analysis.
    Assumes coordinates are Cartesian (ECEF or Local ENU).
    """
    
    # ---------------------------------------------------------
    # 1. Helper: Vector Construction
    # ---------------------------------------------------------
    def get_velocity_vector(speed, heading_deg, bearing_deg):
        """
        Estimates 3D velocity vector from speed and spherical angles.
        Note: We define Heading as Azimuth (0-360) and Bearing as Elevation for 3D context
        OR if Bearing is distinct, we use Heading as the 2D plane direction.
        
        Assumption for this code: 
        Heading = XY plane direction (0 = North/Y, 90 = East/X)
        Bearing = Pitch angle/Elevation (0 = Horizon)
        This is a standard simulation assumption if specific vector components aren't given.
        """
        heading_rad = np.radians(heading_deg)
        # Assuming 'bearing' acts as vertical flight path angle (gamma) here
        # If bearing is actually 2D direction, set pitch to 0.
        pitch_rad = np.radians(bearing_deg) 
        
        vx = speed * np.sin(heading_rad) * np.cos(pitch_rad)
        vy = speed * np.cos(heading_rad) * np.cos(pitch_rad)
        vz = speed * np.sin(pitch_rad)
        
        return np.array([vx, vy, vz])

    # Lists to store new features
    feat_range = []
    feat_closing_vel = []
    feat_los_rate = []
    feat_pursuit_error = []
    feat_aspect_angle = []
    feat_speed_ratio = []
    feat_tti_feasibility = []

    for index, row in df.iterrows():
        # ---------------------------------------------------------
        # 2. Extract State Vectors
        # ---------------------------------------------------------
        # Target Selection
        t_idx = row['it_runner_index']
        
        # Position Vectors (P)
        p_it = np.array(row['it_location']) # [x, y, z]
        p_target = np.array(row['runners_location'][t_idx]) # [x, y, z]
        
        # Velocity Vectors (V)
        # Using the helper to construct 3D vectors from scalar speed/heading
        v_it = get_velocity_vector(
            row['it_speed'], 
            row['it_heading'], 
            row['it_bearing']
        )
        
        v_target = get_velocity_vector(
            row['runner_speed'][t_idx], 
            row['runner_heading'][t_idx], 
            row['runner_bearing'][t_idx]
        )

        # ---------------------------------------------------------
        # 3. Calculate Relative Geometry
        # ---------------------------------------------------------
        # Range Vector (The "Line of Sight" Vector)
        r_vec = p_target - p_it
        dist = np.linalg.norm(r_vec) + 1e-6 # Avoid div/0
        
        # Unit Line of Sight Vector
        u_los = r_vec / dist
        
        # Relative Velocity Vector
        v_rel = v_it - v_target
        
        # ---------------------------------------------------------
        # 4. Compute Top 7 Features
        # ---------------------------------------------------------
        
        # F1: Slant Range
        feat_range.append(dist)
        
        # F2: Closing Velocity
        # Projection of It_Velocity onto LOS (How fast are we approaching?)
        # V_closing is positive when distance is decreasing.
        # Physics definition: - (dR/dt)
        # We project the relative velocity onto the LOS unit vector.
        closing_vel = np.dot(v_rel, u_los)
        feat_closing_vel.append(closing_vel)
        
        # F3: LOS Rate (Guidance Metric)
        # Magnitude of the cross product of Range and Rel_Vel, divided by R^2
        # Measures rotation of the sight-line.
        cross_prod_mag = np.linalg.norm(np.cross(r_vec, v_rel))
        los_rate = cross_prod_mag / (dist**2)
        feat_los_rate.append(los_rate)
        
        # F4: Pure Pursuit Error (Heading Error)
        # Angle between It_Velocity and LOS Vector
        # cos(theta) = (v . u) / (|v| |u|)
        v_it_mag = np.linalg.norm(v_it) + 1e-6
        dot_pursuit = np.dot(v_it, u_los)
        angle_pursuit_rad = np.arccos(np.clip(dot_pursuit / v_it_mag, -1.0, 1.0))
        feat_pursuit_error.append(np.degrees(angle_pursuit_rad))
        
        # F5: Aspect Angle
        # Angle between Target Velocity and LOS Vector
        # If 0 deg, target is running directly away (Tail Chase).
        # If 180 deg, target is flying at us (Head On).
        v_t_mag = np.linalg.norm(v_target) + 1e-6
        dot_aspect = np.dot(v_target, u_los)
        angle_aspect_rad = np.arccos(np.clip(dot_aspect / v_t_mag, -1.0, 1.0))
        feat_aspect_angle.append(np.degrees(angle_aspect_rad))
        
        # F6: Speed Ratio
        speed_ratio = row['it_speed'] / (row['runner_speed'][t_idx] + 1e-6)
        feat_speed_ratio.append(speed_ratio)
        
        # F7: TTI Feasibility
        # How many steps needed vs how many remain?
        if closing_vel > 0:
            steps_needed = dist / closing_vel
            margin = row['remaining_timesteps'] - steps_needed
        else:
            # If closing vel is negative, we are moving away. Infinite/Negative feasibility.
            margin = -999 
        feat_tti_feasibility.append(margin)

    # ---------------------------------------------------------
    # 5. Append to DataFrame
    # ---------------------------------------------------------
    df['fd_range'] = feat_range
    df['fd_closing_vel'] = feat_closing_vel
    df['fd_los_rate'] = feat_los_rate
    df['fd_pursuit_err'] = feat_pursuit_error
    df['fd_aspect_angle'] = feat_aspect_angle
    df['fd_speed_ratio'] = feat_speed_ratio
    df['fd_tti_margin'] = feat_tti_feasibility
    
    return df

# Example Usage:
# df_engineered = engineer_flight_dynamics_features(df)
# print(df_engineered[['outcome', 'fd_range', 'fd_closing_vel', 'fd_los_rate']].head())

=========================================================================================================================================================================
=========================================================================================================================================================================



=========================================================================================================================================================================
=========================================================================================================================================================================



=========================================================================================================================================================================
=========================================================================================================================================================================


=========================================================================================================================================================================
=========================================================================================================================================================================


=========================================================================================================================================================================
=========================================================================================================================================================================


=========================================================================================================================================================================
=========================================================================================================================================================================
Extras

- Anomaly Detection
def _render_table_and_plot(
    df: pd.DataFrame,
    PCs: np.ndarray,
    scores01: np.ndarray,
    raw_scores: np.ndarray,
    method_label: str,
    key_prefix: str,
    pca,  # global PCA (for loadings)
):
    """
    Renders three visual perspectives for a given anomaly method:

      1) Storyboard:
         - Top anomalies table with row selection
         - PCA scatter with optional highlight
         - PCA loading arrows (global + segment-anchored)
         - Segment Comparison & FR correlation
         - Per-selection 'Why this run?' bar chart

      2) Cluster Heatmap:
         - Cluster-vs-feature heatmap in z-score space

      3) Feature Network:
         - Small network of top anomaly-driving features
    """
    df = df.copy()
    df["anomaly_score"] = scores01
    df["raw_anomaly_score"] = raw_scores

    st.markdown(f"### {method_label}")

    tab_story, tab_cluster, tab_network = st.tabs(
        ["Storyboard", "Cluster Heatmap", "Feature Network"]
    )

    # === 1) STORYBOARD TAB ===
    with tab_story:
        # --- Top anomalies: select a row to highlight on the plot ---
        highlight_pos = None
        if show_top > 0:
            cols_keep = [
                "Test_Run_ID",
                "FR",
                "Num_Tests",
                "total_init_time",
                "anomaly_score",
                "raw_anomaly_score",
                "Simulation_Host",
                "Simulation_Node",
                "Capability",
                "Script_File",
                "V",
                "s_number",
                "Build",
            ]
            cols_keep = [c for c in cols_keep if c in df.columns]

            top = df.sort_values("anomaly_score", ascending=False).head(show_top)

            st.markdown("**Top anomalies**")
            editable = top[cols_keep].copy()
            editable.insert(0, "Select", False)

            edited = st.data_editor(
                editable,
                use_container_width=True,
                num_rows="fixed",
                disabled={c: True for c in editable.columns if c != "Select"},
                key=f"{key_prefix}-table",
            )

            selected_original_idxs = edited.index[edited["Select"]].tolist()
            if selected_original_idxs:
                pos = df.index.get_indexer([selected_original_idxs[0]])
                if len(pos) and pos[0] != -1:
                    highlight_pos = int(pos[0])

        # --- PCA plot with optional highlight ---
        fig = plot_for_df(df, PCs, label_choice, highlight_pos=highlight_pos)

        # === Driver arrows overlays (global + low/high FR anchors) ===
        if show_biplot and PCs.shape[1] >= 2 and pca is not None:
            # 1) Global arrows from origin
            try:
                add_pca_loadings_3d(fig, pca, PCA_FEATURES, scale=2.0)
            except Exception:
                pass

            # 2) Segment-anchored arrows near Low-FR and High-FR bands
            try:
                seg = make_fr_segments(df)  # "Low FR" / "Mid FR" / "High FR"
                # Low-FR centroid
                low_mask = (seg == "Low FR").values
                if np.any(low_mask):
                    low_anchor = PCs[low_mask].mean(axis=0)
                    add_biplot_arrows_at_anchor_3d(
                        fig,
                        pca,
                        PCA_FEATURES,
                        low_anchor,
                        scale=1.2,
                        color="green",
                        name_prefix="Low FR ",
                        showlegend=False,
                    )
                # High-FR centroid
                high_mask = (seg == "High FR").values
                if np.any(high_mask):
                    high_anchor = PCs[high_mask].mean(axis=0)
                    add_biplot_arrows_at_anchor_3d(
                        fig,
                        pca,
                        PCA_FEATURES,
                        high_anchor,
                        scale=1.2,
                        color="red",
                        name_prefix="High FR ",
                        showlegend=False,
                    )
            except Exception:
                pass

        st.plotly_chart(fig, use_container_width=True, key=f"{key_prefix}-plot")

        # --- Segment Comparison + FR Correlation ---
        if show_segment_compare:
            c1, c2 = st.columns([2, 1])
            with c1:
                st.markdown("#### Segment Comparison: Low vs High FR")
                st.plotly_chart(
                    segment_diff_bar(df),
                    use_container_width=True,
                    key=f"{key_prefix}-segdiff",
                )
            with c2:
                st.markdown("#### FR Correlation")
                st.plotly_chart(
                    fr_correlation_heatmap(df),
                    use_container_width=True,
                    key=f"{key_prefix}-frcorr",
                )

        # --- Per-selection “Why this run?” ---
        if show_selection_why and highlight_pos is not None:
            st.markdown("#### Why this run?")
            st.plotly_chart(
                per_point_contribution_bar(df, highlight_pos),
                use_container_width=True,
                key=f"{key_prefix}-whybar",
            )

    # === 2) CLUSTER HEATMAP TAB ===
    with tab_cluster:
        st.markdown("#### Cluster-level feature patterns")
        st.plotly_chart(
            cluster_profile_heatmap(df, PCs, scores01),
            use_container_width=True,
            key=f"{key_prefix}-clusterheat",
        )

    # === 3) FEATURE NETWORK TAB ===
    with tab_network:
        # Use the most anomalous subset to focus the network
        n_sub = max(20, int(0.2 * len(df)))
        df_anom = df.sort_values("anomaly_score", ascending=False).head(n_sub)
        st.markdown("#### Relationships among top anomaly-driving features")
        st.plotly_chart(
            feature_influence_network_figure(df_anom),
            use_container_width=True,
            key=f"{key_prefix}-featnet",
        )


