# =========================
# Sidebar (remove single-method selector; keep dataset controls)
# =========================
st.sidebar.header("Controls")

dataset_names = [p.name for p in csv_paths]  # or dataset_labels if you built them
selected_idx = st.sidebar.selectbox("Dataset",
                                    options=list(range(len(dataset_names))),
                                    format_func=lambda i: dataset_names[i],
                                    index=0)
show_all = st.sidebar.checkbox("Show all datasets", value=False)
label_choice = st.sidebar.selectbox("Color/Group by", list(LABEL_DICT.keys()))
show_top = st.sidebar.number_input("Show Top-N anomalies table per dataset (0 to hide)",
                                   min_value=0, max_value=1000, value=10, step=1)

# Optional per-method knobs (global)
if_contam = st.sidebar.slider("IF: Contamination (expected anomaly %)", 0.0, 0.2, 0.02, 0.005)
if_trees  = st.sidebar.slider("IF: Trees (n_estimators)", 100, 1000, 300, 50)
lof_k     = st.sidebar.slider("LOF: Neighbors (n_neighbors)", 5, 100, 20, 1)
ae_w1     = st.sidebar.slider("AE: Hidden size 1", 4, 64, 16, 2)
ae_w2     = st.sidebar.slider("AE: Bottleneck", 2, 32, 8, 1)
ae_w3     = st.sidebar.slider("AE: Hidden size 3", 4, 64, 16, 2)
ae_iter   = st.sidebar.slider("AE: Max epochs", 100, 1000, 400, 50)

# =========================
# Utility to render a single tab (table + plot with highlight)
# =========================
def _render_table_and_plot(df: pd.DataFrame, PCs: np.ndarray, scores01: np.ndarray, raw_scores: np.ndarray, method_label: str):
    df = df.copy()
    df["anomaly_score"] = scores01
    df["raw_anomaly_score"] = raw_scores

    st.markdown(f"### {method_label}")
    highlight_pos = None
    if show_top > 0:
        cols_keep = ["Test_Run_ID","FR","Num_Tests","total_init_time","anomaly_score","raw_anomaly_score",
                     "Simulation_Host","Simulation_Node","Capability","Script_File","V","s_number","Build"]
        cols_keep = [c for c in cols_keep if c in df.columns]
        top = df.sort_values("anomaly_score", ascending=False).head(show_top)

        st.markdown("**Top anomalies**")
        editable = top[cols_keep].copy()
        editable.insert(0, "Select", False)
        edited = st.data_editor(
            editable,
            use_container_width=True,
            num_rows="fixed",
            disabled={c: True for c in editable.columns if c != "Select"}
        )
        selected_original_idxs = edited.index[edited["Select"]].tolist()
        if selected_original_idxs:
            pos = df.index.get_indexer([selected_original_idxs[0]])
            if len(pos) and pos[0] != -1:
                highlight_pos = int(pos[0])

    fig = plot_for_df(df, PCs, label_choice, highlight_pos=highlight_pos)
    st.plotly_chart(fig, use_container_width=True)

# =========================
# New render_one: compute all methods + consensus; show tabs
# =========================
def render_one(path: Path):
    try:
        raw = load_csv(path)
        df = engineer_features(raw)

        # Features + scaling once
        X = build_features(df).to_numpy(dtype=float)
        Xz, _ = scale_features(df)

        # PCA only for viz
        _, _, _, PCs = fit_pca_scaled(X, n_components=3)

        # Score each method
        _, if_raw  = score_isolation_forest(Xz, contamination=if_contam, n_estimators=if_trees)
        _, lof_raw = score_lof(Xz, n_neighbors=lof_k)
        _, ae_raw  = score_autoencoder(Xz, hidden=(ae_w1, ae_w2, ae_w3), max_iter=ae_iter)

        if_s01  = normalize_scores(if_raw)
        lof_s01 = normalize_scores(lof_raw)
        ae_s01  = normalize_scores(ae_raw)

        # Consensus: mean rank across methods (lower rank = more anomalous)
        import numpy as np
        def ranks(arr):
            # rank 1 = most anomalous (highest score), so reverse sort
            order = np.argsort(-arr)
            inv = np.empty_like(order)
            inv[order] = np.arange(1, len(arr)+1)
            return inv.astype(float)

        r_if, r_lof, r_ae = ranks(if_s01), ranks(lof_s01), ranks(ae_s01)
        consensus_rank = (r_if + r_lof + r_ae) / 3.0
        # Convert consensus to a 0-1 score for coloring (invert: higher = more anomalous)
        # Use normalized inverse ranks
        cons_score01 = normalize_scores((1.0 / consensus_rank))

        st.subheader(f"{path.name} Â· Multi-Method Anomaly Analysis")

        tab_if, tab_lof, tab_ae, tab_cons = st.tabs([
            "Isolation Forest", "Local Outlier Factor", "Autoencoder", "Consensus"
        ])

        with tab_if:
            _render_table_and_plot(df, PCs, if_s01, if_raw, "Isolation Forest")

        with tab_lof:
            _render_table_and_plot(df, PCs, lof_s01, lof_raw, "Local Outlier Factor")

        with tab_ae:
            _render_table_and_plot(df, PCs, ae_s01, ae_raw, "Autoencoder (Reconstruction)")

        with tab_cons:
            # For consensus, "raw" is the mean rank (lower = worse); we show both.
            _render_table_and_plot(
                df.assign(consensus_rank=consensus_rank),
                PCs,
                cons_score01,
                consensus_rank,  # raw
                "Consensus (mean rank of IF, LOF, AE)"
            )

    except Exception as e:
        st.error(f"Failed to process {path.name}: {e}")
