# =========================
# New render_one: compute all methods + consensus; show tabs
# =========================
def render_one(path: Path):
    try:
        raw = load_csv(path)
        df = engineer_features(raw)

        # Features + scaling once
        X = build_features(df).to_numpy(dtype=float)
        Xz, _ = scale_features(df)

        # PCA only for viz
        _, _, _, PCs = fit_pca_scaled(X, n_components=3)

        # Score each method
        _, if_raw  = score_isolation_forest(Xz, contamination=if_contam, n_estimators=if_trees)
        _, lof_raw = score_lof(Xz, n_neighbors=lof_k)
        _, ae_raw  = score_autoencoder(Xz, hidden=(ae_w1, ae_w2, ae_w3), max_iter=ae_iter)

        if_s01  = normalize_scores(if_raw)
        lof_s01 = normalize_scores(lof_raw)
        ae_s01  = normalize_scores(ae_raw)

        # Consensus: mean rank across methods (lower rank = more anomalous)
        import numpy as np
        def ranks(arr):
            # rank 1 = most anomalous (highest score), so reverse sort
            order = np.argsort(-arr)
            inv = np.empty_like(order)
            inv[order] = np.arange(1, len(arr)+1)
            return inv.astype(float)

        r_if, r_lof, r_ae = ranks(if_s01), ranks(lof_s01), ranks(ae_s01)
        consensus_rank = (r_if + r_lof + r_ae) / 3.0
        # Convert consensus to a 0-1 score for coloring (invert: higher = more anomalous)
        # Use normalized inverse ranks
        cons_score01 = normalize_scores((1.0 / consensus_rank))

        st.subheader(f"{path.name} Â· Multi-Method Anomaly Analysis")

        tab_if, tab_lof, tab_ae, tab_cons = st.tabs([
            "Isolation Forest", "Local Outlier Factor", "Autoencoder", "Consensus"
        ])

        with tab_if:
            _render_table_and_plot(df, PCs, if_s01, if_raw, "Isolation Forest")

        with tab_lof:
            _render_table_and_plot(df, PCs, lof_s01, lof_raw, "Local Outlier Factor")

        with tab_ae:
            _render_table_and_plot(df, PCs, ae_s01, ae_raw, "Autoencoder (Reconstruction)")

        with tab_cons:
            # For consensus, "raw" is the mean rank (lower = worse); we show both.
            _render_table_and_plot(
                df.assign(consensus_rank=consensus_rank),
                PCs,
                cons_score01,
                consensus_rank,  # raw
                "Consensus (mean rank of IF, LOF, AE)"
            )

    except Exception as e:
        st.error(f"Failed to process {path.name}: {e}")
