# === VISUAL ANALYTICS HELPERS ===
import plotly.graph_objects as go
import numpy as np
import pandas as pd

FEATURES_FOR_ANALYSIS = ["P","F","B","U","total_init_time","FR","Num_Tests"]

def zscore_frame(df: pd.DataFrame, cols: list[str]) -> pd.DataFrame:
    z = df[cols].astype(float)
    mu = z.mean(axis=0)
    sd = z.std(axis=0).replace(0, 1.0)
    return (z - mu) / sd

def make_fr_segments(df: pd.DataFrame) -> pd.Series:
    # Low / Mid / High by FR quartiles (emphasize extremes)
    q25, q75 = df["FR"].quantile([0.25, 0.75])
    seg = pd.Series(np.where(df["FR"] >= q75, "High FR",
                     np.where(df["FR"] <= q25, "Low FR", "Mid FR")),
                    index=df.index, name="FR_Segment")
    return seg

def segment_diff_bar(df: pd.DataFrame) -> go.Figure:
    # Compare Low vs High in normalized space
    seg = make_fr_segments(df)
    z = zscore_frame(df, FEATURES_FOR_ANALYSIS)
    low = z[seg == "Low FR"].mean()
    high = z[seg == "High FR"].mean()
    diff = (high - low).sort_values(key=lambda s: s.abs(), ascending=False)

    fig = go.Figure()
    fig.add_bar(x=diff.index, y=diff.values)
    fig.update_layout(
        title="Feature Difference (High FR − Low FR) [z-score]",
        xaxis_title="Feature",
        yaxis_title="Δ z-score (higher ⇒ higher in High-FR segment)",
        height=360, margin=dict(l=10, r=10, t=40, b=60)
    )
    return fig

def fr_correlation_heatmap(df: pd.DataFrame) -> go.Figure:
    cols = FEATURES_FOR_ANALYSIS
    corr = df[cols + ["FR"]].corr().loc[cols, ["FR"]].round(3)
    fig = go.Figure(data=go.Heatmap(
        z=corr.values.T, x=cols, y=["FR"], text=corr.values.T, texttemplate="%{text}",
        zmin=-1, zmax=1, colorbar=dict(title="corr")
    ))
    fig.update_layout(title="Correlation with FR", height=220, margin=dict(l=10, r=10, t=40, b=10))
    return fig

def add_pca_loadings_3d(fig: go.Figure, pca, feature_names: list[str], scale: float = 2.0):
    """
    Overlay PCA loading arrows (components) for first 3 PCs.
    """
    loadings = pca.components_.T  # shape: (n_features, n_components)
    k = min(3, loadings.shape[1])
    for i, fname in enumerate(feature_names):
        vec = loadings[i, :k] * scale
        if k == 3:
            x, y, z = [0, vec[0]], [0, vec[1]], [0, vec[2]]
            fig.add_trace(go.Scatter3d(x=x, y=y, z=z, mode="lines",
                                       line=dict(width=5), name=f"→ {fname}", showlegend=False))
            # text label at arrow tip
            fig.add_trace(go.Scatter3d(x=[vec[0]], y=[vec[1]], z=[vec[2]],
                                       mode="text", text=[fname], showlegend=False))
        elif k == 2:
            # Fallback 2D
            x, y = [0, vec[0]], [0, vec[1]]
            fig.add_trace(go.Scatter(x=x, y=y, mode="lines+text",
                                     text=[None, fname], textposition="top center", showlegend=False))
    return fig

def per_point_contribution_bar(df: pd.DataFrame, row_pos: int) -> go.Figure:
    """
    Show top-5 z-score deviations for a selected point (why it's weird).
    """
    z = zscore_frame(df, FEATURES_FOR_ANALYSIS)
    if row_pos < 0 or row_pos >= len(z):
        row_pos = 0
    row = z.iloc[row_pos].abs().sort_values(ascending=False).head(5)
    # Use signed values for direction
    signed = z.iloc[row_pos][row.index]
    fig = go.Figure(go.Bar(x=signed.index, y=signed.values))
    fig.update_layout(
        title="Why this run? Top deviations (z-scores)",
        xaxis_title="Feature",
        yaxis_title="Deviation (±σ)",
        height=300, margin=dict(l=10, r=10, t=40, b=40)
    )
    return fig



=========================================================================================================================================================================
=========================================================================================================================================================================

# === Visual analytics toggles ===
st.sidebar.subheader("Root-Cause Visuals")
show_biplot = st.sidebar.checkbox("Show PCA driver arrows (feature loadings)", value=True)
show_segment_compare = st.sidebar.checkbox("Show Low-vs-High FR compare", value=True)
show_selection_why = st.sidebar.checkbox("Show 'Why this run?' panel", value=True)




=========================================================================================================================================================================
=========================================================================================================================================================================

# BEFORE you had:
# _, _, _, PCs = fit_pca_scaled(X, n_components=3)

scaler, pca, Xz_unused, PCs = fit_pca_scaled(X, n_components=3)

=========================================================================================================================================================================
=========================================================================================================================================================================

fig = plot_for_df(df, PCs, label_choice, highlight_pos=highlight_pos)

# NEW: overlay PCA driver arrows (biplot) for first 3 PCs
if show_biplot and PCs.shape[1] >= 2:
    try:
        add_pca_loadings_3d(fig, pca, FEATURES_FOR_ANALYSIS, scale=2.0)
    except Exception:
        pass

st.plotly_chart(fig, use_container_width=True, key=f"{path.name}-rootplot")


=========================================================================================================================================================================
=========================================================================================================================================================================

# NEW: Segment Compare & Correlation
if show_segment_compare:
    c1, c2 = st.columns([2, 1])
    with c1:
        st.markdown("#### Segment Comparison: Low vs High FR")
        st.plotly_chart(segment_diff_bar(df), use_container_width=True, key=f"{path.name}-segdiff")
    with c2:
        st.markdown("#### FR Correlation")
        st.plotly_chart(fr_correlation_heatmap(df), use_container_width=True, key=f"{path.name}-frcorr")


=========================================================================================================================================================================
=========================================================================================================================================================================

# NEW: Per-selection "Why" panel (uses the row selected in Top anomalies)
if show_selection_why and highlight_pos is not None:
    st.markdown("#### Why this run?")
    st.plotly_chart(per_point_contribution_bar(df, highlight_pos),
                    use_container_width=True, key=f"{path.name}-whybar")

=========================================================================================================================================================================
=========================================================================================================================================================================
def _render_table_and_plot(
    df: pd.DataFrame,
    PCs: np.ndarray,
    scores01: np.ndarray,
    raw_scores: np.ndarray,
    method_label: str,
    key_prefix: str,
    pca,  # NEW: needed for PCA driver arrows
):
    """
    Renders:
      1) Top anomalies table with row selection
      2) PCA scatter with optional highlight + PCA loading arrows (biplot)
      3) Segment Comparison & FR correlation panels (optional)
      4) Per-selection 'Why this run?' panel (optional)
    """
    df = df.copy()
    df["anomaly_score"] = scores01
    df["raw_anomaly_score"] = raw_scores

    st.markdown(f"### {method_label}")

    # --- Top anomalies: select a row to highlight on the plot ---
    highlight_pos = None
    if show_top > 0:
        cols_keep = [
            "Test_Run_ID", "FR", "Num_Tests", "total_init_time",
            "anomaly_score", "raw_anomaly_score",
            "Simulation_Host", "Simulation_Node", "Capability",
            "Script_File", "V", "s_number", "Build"
        ]
        cols_keep = [c for c in cols_keep if c in df.columns]

        top = df.sort_values("anomaly_score", ascending=False).head(show_top)

        st.markdown("**Top anomalies**")
        editable = top[cols_keep].copy()
        editable.insert(0, "Select", False)

        edited = st.data_editor(
            editable,
            use_container_width=True,
            num_rows="fixed",
            disabled={c: True for c in editable.columns if c != "Select"},
            key=f"{key_prefix}-table"
        )

        selected_original_idxs = edited.index[edited["Select"]].tolist()
        if selected_original_idxs:
            pos = df.index.get_indexer([selected_original_idxs[0]])
            if len(pos) and pos[0] != -1:
                highlight_pos = int(pos[0])

    # --- PCA plot with optional highlight ---
    fig = plot_for_df(df, PCs, label_choice, highlight_pos=highlight_pos)

    # NEW: overlay PCA driver arrows (feature loadings) for first 2–3 PCs
    if show_biplot and PCs.shape[1] >= 2 and pca is not None:
        try:
            add_pca_loadings_3d(fig, pca, FEATURES_FOR_ANALYSIS, scale=2.0)
        except Exception:
            pass

    st.plotly_chart(fig, use_container_width=True, key=f"{key_prefix}-plot")

    # NEW: Segment Comparison + FR Correlation (below the plot)
    if show_segment_compare:
        c1, c2 = st.columns([2, 1])
        with c1:
            st.markdown("#### Segment Comparison: Low vs High FR")
            st.plotly_chart(
                segment_diff_bar(df),
                use_container_width=True,
                key=f"{key_prefix}-segdiff"
            )
        with c2:
            st.markdown("#### FR Correlation")
            st.plotly_chart(
                fr_correlation_heatmap(df),
                use_container_width=True,
                key=f"{key_prefix}-frcorr"
            )

    # NEW: Per-selection “Why this run?” (uses z-score deviations)
    if show_selection_why and highlight_pos is not None:
        st.markdown("#### Why this run?")
        st.plotly_chart(
            per_point_contribution_bar(df, highlight_pos),
            use_container_width=True,
            key=f"{key_prefix}-whybar"
        )


=========================================================================================================================================================================
=========================================================================================================================================================================

def render_one(path: Path):
    """
    Loads a dataset, computes features, runs all anomaly methods (IF/LOF/AE),
    builds PCA for visualization, and renders four tabs:
      - Isolation Forest
      - Local Outlier Factor
      - Autoencoder (reconstruction)
      - Consensus (mean rank across methods)
    Each tab shows the Top anomalies table with selection-driven highlight,
    the PCA plot (with optional driver arrows), and the visual root-cause panels.
    """
    try:
        raw = load_csv(path)
        df = engineer_features(raw)

        # Features + scaling once
        X = build_features(df).to_numpy(dtype=float)
        Xz, _ = scale_features(df)

        # PCA ONLY for visualization (capture pca object for biplot arrows)
        scaler_viz, pca_viz, _, PCs = fit_pca_scaled(X, n_components=3)

        # Score each method
        _, if_raw  = score_isolation_forest(Xz, contamination=if_contam, n_estimators=if_trees)
        _, lof_raw = score_lof(Xz, n_neighbors=lof_k)
        _, ae_raw  = score_autoencoder(Xz, hidden=(ae_w1, ae_w2, ae_w3), max_iter=ae_iter)

        if_s01  = normalize_scores(if_raw)
        lof_s01 = normalize_scores(lof_raw)
        ae_s01  = normalize_scores(ae_raw)

        # Consensus: mean rank across methods (lower rank = more anomalous)
        import numpy as np
        def ranks(arr):
            order = np.argsort(-arr)       # higher score = more anomalous
            inv = np.empty_like(order)
            inv[order] = np.arange(1, len(arr) + 1)
            return inv.astype(float)

        r_if, r_lof, r_ae = ranks(if_s01), ranks(lof_s01), ranks(ae_s01)
        consensus_rank = (r_if + r_lof + r_ae) / 3.0
        cons_score01 = normalize_scores((1.0 / consensus_rank))  # invert rank for [0,1] score

        st.subheader(f"{path.name} · Multi-Method Anomaly Analysis")

        tab_if, tab_lof, tab_ae, tab_cons = st.tabs([
            "Isolation Forest", "Local Outlier Factor", "Autoencoder", "Consensus"
        ])

        with tab_if:
            _render_table_and_plot(
                df, PCs, if_s01, if_raw,
                "Isolation Forest",
                key_prefix=f"{path.name}-IF",
                pca=pca_viz
            )

        with tab_lof:
            _render_table_and_plot(
                df, PCs, lof_s01, lof_raw,
                "Local Outlier Factor",
                key_prefix=f"{path.name}-LOF",
                pca=pca_viz
            )

        with tab_ae:
            _render_table_and_plot(
                df, PCs, ae_s01, ae_raw,
                "Autoencoder (Reconstruction)",
                key_prefix=f"{path.name}-AE",
                pca=pca_viz
            )

        with tab_cons:
            _render_table_and_plot(
                df.assign(consensus_rank=consensus_rank),
                PCs,
                cons_score01,
                consensus_rank,  # raw = mean rank
                "Consensus (mean rank of IF, LOF, AE)",
                key_prefix=f"{path.name}-CONS",
                pca=pca_viz
            )

    except Exception as e:
        st.error(f"Failed to process {path.name}: {e}")

