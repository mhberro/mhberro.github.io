
# ---- Session State Defaults for Controls ----
if "active_primary" not in st.session_state:
    st.session_state["active_primary"] = "PCA"

if "active_secondary" not in st.session_state:
    st.session_state["active_secondary"] = "Storyboard"

# Global-ish controls
if "label_choice" not in st.session_state:
    st.session_state["label_choice"] = "Failure Rate"  # or whatever default label name you use

if "show_top" not in st.session_state:
    st.session_state["show_top"] = 10

# PCA / visualization toggles
for key, default in {
    "show_biplot": True,
    "pca_arrow_features": [],
    "show_global_pca_arrows": True,
    "show_low_fr_arrows": True,
    "show_high_fr_arrows": True,
    "show_segment_compare": True,
    "show_selection_why": True,
    "show_influence_network": True,
    "influence_subset": "Anomalous (top 5%)",
    "influence_topk": 10,
    "influence_edge_thresh": 0.40,
    "influence_corr_method": "pearson",
}.items():
    if key not in st.session_state:
        st.session_state[key] = default

# Method hyperparameters
if "if_contam" not in st.session_state:
    st.session_state["if_contam"] = 0.02
if "if_trees" not in st.session_state:
    st.session_state["if_trees"] = 300
if "lof_k" not in st.session_state:
    st.session_state["lof_k"] = 20

# Dataset selection
if "selected_dataset_idx" not in st.session_state:
    st.session_state["selected_dataset_idx"] = 0





=========================================================================================================================================================================
=========================================================================================================================================================================
def render_sidebar_controls(
    csv_paths: list[Path],
    dataset_labels: list[str],
    LABEL_DICT: dict,
    PCA_FEATURES: list[str],
):
    """Dynamic sidebar that shows controls relevant to the visible graphics."""
    st.sidebar.header("Controls")

    # ---- Dataset selection & global labeling ----
    dataset_label_list = dataset_labels or [p.name for p in csv_paths]

    selected_idx = st.sidebar.selectbox(
        "Dataset",
        options=list(range(len(dataset_label_list))),
        format_func=lambda i: dataset_label_list[i],
        index=st.session_state.get("selected_dataset_idx", 0),
        key="selected_dataset_idx",
    )

    show_all = st.sidebar.checkbox(
        "Show all datasets",
        value=False,
        key="sidebar_show_all_datasets",   # IMPORTANT: unique key
    )

    st.sidebar.subheader("Color / Group by")
    label_choice = st.sidebar.selectbox(
        "Label",
        options=list(LABEL_DICT.keys()),
        index=list(LABEL_DICT.keys()).index(st.session_state.get("label_choice", list(LABEL_DICT.keys())[0])),
        key="label_choice",
    )

    show_top = st.sidebar.number_input(
        "Top-N anomalies table (0 to hide)",
        min_value=0,
        max_value=1000,
        value=st.session_state.get("show_top", 10),
        step=1,
        key="show_top",
    )

    st.sidebar.divider()
    st.sidebar.subheader("Method-Specific")

    primary = st.session_state.get("active_primary", "PCA")
    secondary = st.session_state.get("active_secondary", "Storyboard")

    # ---- PCA-specific controls ----
    if primary == "PCA":
        st.sidebar.markdown("**PCA Visualization**")
        st.sidebar.checkbox(
            "Show PCA driver arrows",
            value=st.session_state.get("show_biplot", True),
            key="show_biplot",
        )

        st.sidebar.multiselect(
            "PCA driver arrows (numeric features)",
            PCA_FEATURES,
            default=st.session_state.get("pca_arrow_features", PCA_FEATURES),
            key="pca_arrow_features",
        )

        st.sidebar.checkbox(
            "Show global arrows (from origin)",
            value=st.session_state.get("show_global_pca_arrows", True),
            key="show_global_pca_arrows",
        )

        st.sidebar.checkbox(
            "Show Low-FR cluster arrows",
            value=st.session_state.get("show_low_fr_arrows", True),
            key="show_low_fr_arrows",
        )

        st.sidebar.checkbox(
            "Show High-FR cluster arrows",
            value=st.session_state.get("show_high_fr_arrows", True),
            key="show_high_fr_arrows",
        )

        # Storyboard-specific controls
        if secondary == "Storyboard":
            st.sidebar.markdown("**Storyboard Options**")
            st.sidebar.checkbox(
                "Show segment comparison (z-scores / % share)",
                value=st.session_state.get("show_segment_compare", True),
                key="show_segment_compare",
            )
            st.sidebar.checkbox(
                "Show 'Why this run?' panel",
                value=st.session_state.get("show_selection_why", True),
                key="show_selection_why",
            )

        # Influence network-specific controls
        if secondary == "Anomaly Influence Network":
            st.sidebar.markdown("**Anomaly Influence Network**")
            st.sidebar.selectbox(
                "Subset",
                ["Anomalous (top 5%)", "Normal (bottom 5%)", "All runs"],
                index=["Anomalous (top 5%)", "Normal (bottom 5%)", "All runs"].index(
                    st.session_state.get("influence_subset", "Anomalous (top 5%)")
                ),
                key="influence_subset",
            )
            st.sidebar.slider(
                "Top-K features",
                min_value=4,
                max_value=15,
                value=st.session_state.get("influence_topk", 10),
                step=1,
                key="influence_topk",
            )
            st.sidebar.slider(
                "Edge threshold (|corr|)",
                min_value=0.10,
                max_value=0.90,
                value=st.session_state.get("influence_edge_thresh", 0.40),
                step=0.05,
                key="influence_edge_thresh",
            )
            st.sidebar.selectbox(
                "Correlation method",
                ["pearson", "spearman"],
                index=["pearson", "spearman"].index(
                    st.session_state.get("influence_corr_method", "pearson")
                ),
                key="influence_corr_method",
            )
            st.sidebar.checkbox(
                "Show Anomaly Influence Network",
                value=st.session_state.get("show_influence_network", True),
                key="show_influence_network",
            )

    # ---- Isolation Forest controls ----
    if primary == "Isolation Forest":
        st.sidebar.markdown("**Isolation Forest**")
        st.sidebar.slider(
            "IF: Contamination (expected anomaly %)",
            min_value=0.0,
            max_value=0.2,
            value=st.session_state.get("if_contam", 0.02),
            step=0.005,
            key="if_contam",
        )
        st.sidebar.slider(
            "IF: Trees (n_estimators)",
            min_value=100,
            max_value=1000,
            value=st.session_state.get("if_trees", 300),
            step=50,
            key="if_trees",
        )

        if secondary == "Storyboard":
            st.sidebar.markdown("**Storyboard Options**")
            st.sidebar.checkbox(
                "Show segment comparison (z-scores / % share)",
                value=st.session_state.get("show_segment_compare", True),
                key="show_segment_compare",
            )
            st.sidebar.checkbox(
                "Show 'Why this run?' panel",
                value=st.session_state.get("show_selection_why", True),
                key="show_selection_why",
            )

        if secondary == "Anomaly Influence Network":
            st.sidebar.markdown("**Anomaly Influence Network**")
            st.sidebar.selectbox(
                "Subset",
                ["Anomalous (top 5%)", "Normal (bottom 5%)", "All runs"],
                index=["Anomalous (top 5%)", "Normal (bottom 5%)", "All runs"].index(
                    st.session_state.get("influence_subset", "Anomalous (top 5%)")
                ),
                key="influence_subset",
            )
            st.sidebar.slider(
                "Top-K features",
                min_value=4,
                max_value=15,
                value=st.session_state.get("influence_topk", 10),
                step=1,
                key="influence_topk",
            )
            st.sidebar.slider(
                "Edge threshold (|corr|)",
                min_value=0.10,
                max_value=0.90,
                value=st.session_state.get("influence_edge_thresh", 0.40),
                step=0.05,
                key="influence_edge_thresh",
            )
            st.sidebar.selectbox(
                "Correlation method",
                ["pearson", "spearman"],
                index=["pearson", "spearman"].index(
                    st.session_state.get("influence_corr_method", "pearson")
                ),
                key="influence_corr_method",
            )
            st.sidebar.checkbox(
                "Show Anomaly Influence Network",
                value=st.session_state.get("show_influence_network", True),
                key="show_influence_network",
            )

    # ---- LOF controls ----
    if primary == "Local Outlier Factor":
        st.sidebar.markdown("**Local Outlier Factor**")
        st.sidebar.slider(
            "LOF: Neighbors (n_neighbors)",
            min_value=5,
            max_value=100,
            value=st.session_state.get("lof_k", 20),
            step=1,
            key="lof_k",
        )

        if secondary == "Storyboard":
            st.sidebar.markdown("**Storyboard Options**")
            st.sidebar.checkbox(
                "Show segment comparison (z-scores / % share)",
                value=st.session_state.get("show_segment_compare", True),
                key="show_segment_compare",
            )
            st.sidebar.checkbox(
                "Show 'Why this run?' panel",
                value=st.session_state.get("show_selection_why", True),
                key="show_selection_why",
            )

        if secondary == "Anomaly Influence Network":
            st.sidebar.markdown("**Anomaly Influence Network**")
            st.sidebar.selectbox(
                "Subset",
                ["Anomalous (top 5%)", "Normal (bottom 5%)", "All runs"],
                index=["Anomalous (top 5%)", "Normal (bottom 5%)", "All runs"].index(
                    st.session_state.get("influence_subset", "Anomalous (top 5%)")
                ),
                key="influence_subset",
            )
            st.sidebar.slider(
                "Top-K features",
                min_value=4,
                max_value=15,
                value=st.session_state.get("influence_topk", 10),
                step=1,
                key="influence_topk",
            )
            st.sidebar.slider(
                "Edge threshold (|corr|)",
                min_value=0.10,
                max_value=0.90,
                value=st.session_state.get("influence_edge_thresh", 0.40),
                step=0.05,
                key="influence_edge_thresh",
            )
            st.sidebar.selectbox(
                "Correlation method",
                ["pearson", "spearman"],
                index=["pearson", "spearman"].index(
                    st.session_state.get("influence_corr_method", "pearson")
                ),
                key="influence_corr_method",
            )
            st.sidebar.checkbox(
                "Show Anomaly Influence Network",
                value=st.session_state.get("show_influence_network", True),
                key="show_influence_network",
            )

    return {
        "selected_idx": selected_idx,
        "show_all": show_all,
    }


=========================================================================================================================================================================
=========================================================================================================================================================================

# Assume:
#   csv_paths: List[Path]
#   dataset_labels: List[str] (same length as csv_paths)
#   LABEL_DICT, PCA_FEATURES already defined

sidebar_state = render_sidebar_controls(
    csv_paths=csv_paths,
    dataset_labels=dataset_labels,
    LABEL_DICT=LABEL_DICT,
    PCA_FEATURES=PCA_FEATURES,
)

selected_idx = sidebar_state["selected_idx"]
show_all = sidebar_state["show_all"]

if show_all:
    for path in csv_paths:
        render_one(path)
        st.divider()
else:
    render_one(csv_paths[selected_idx])


=========================================================================================================================================================================
=========================================================================================================================================================================

=========================================================================================================================================================================
=========================================================================================================================================================================
kinematic-classifier

# conftest.py (alternative)
import pytest, shutil
from pathlib import Path

@pytest.fixture()
def repo_data_files_with_fakes(tmp_path, monkeypatch):
    root = Path(__file__).resolve().parents[1]
    fake_src = root / "data" / "fake_data_files"
    real_dst = root / "my_pkg" / "data" / "data_files"

    backups = []
    real_dst.mkdir(parents=True, exist_ok=True)

    # backup any existing files, then copy fakes
    for f in real_dst.glob("*"):
        b = tmp_path / f.name
        shutil.copy2(f, b)
        backups.append((f, b))
    for f in fake_src.iterdir():
        if f.is_file():
            shutil.copy2(f, real_dst / f.name)

    yield real_dst  # tests run with fakes in place

    # restore previous contents
    for f in real_dst.glob("*"):
        f.unlink()
    for dst, backup in backups:
        shutil.copy2(backup, dst)

=========================================================================================================================================================================
=========================================================================================================================================================================




=========================================================================================================================================================================
=========================================================================================================================================================================
PG-35: Susceptibility Modeling


import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

sns.set(style="whitegrid")

# Make sure outcome is a clean categorical
df["outcome"] = df["outcome"].astype(str)

# Palette for negative/positive outcome
palette_light = {
    "TAGGED":   "#e57373",  # light red
    "UNTAGGED": "#81c784",  # light green
    "tag":      "#e57373",
    "untag":    "#81c784",
}

# 1.1 Basic summary
print("=== BASIC INFO ===")
print(df[["target_distance", "closing_speed", "heading_diff",
          "remaining_timesteps", "outcome"]].describe(include="all"))
print("\nOutcome value counts:")
print(df["outcome"].value_counts(dropna=False))

# 1.2 Joint distribution: distance vs closing_speed
plt.figure(figsize=(9, 7))

sns.kdeplot(
    data=df,
    x="target_distance",
    y="closing_speed",
    fill=True,
    thresh=0.1,
    levels=20,
    cmap="Greys",
    alpha=0.3,
)

sns.scatterplot(
    data=df,
    x="target_distance",
    y="closing_speed",
    hue="outcome",
    palette=palette_light,
    edgecolor="k",
    s=40,
    alpha=0.8,
)

plt.title("Joint Distribution: Target Distance vs Closing Speed")
plt.xlabel("Target Distance (ECEF meters)")
plt.ylabel("Closing Speed (it_speed - target_speed)")
plt.legend(title="Outcome")
plt.tight_layout()
plt.show()

# 1.3 Distribution comparison: key features by outcome
key_features = ["target_distance", "closing_speed", "heading_diff", "remaining_timesteps"]

for feat in key_features:
    plt.figure(figsize=(8, 6))
    sns.histplot(
        data=df,
        x=feat,
        hue="outcome",
        bins=40,
        kde=True,
        palette=palette_light,
        alpha=0.6,
    )
    plt.title(f"Distribution of {feat} by Outcome")
    plt.xlabel(feat)
    plt.ylabel("Count")
    plt.tight_layout()
    plt.show()

# 1.4 Correlation heatmap for numeric features
numeric_cols = ["target_distance", "closing_speed", "heading_diff", "remaining_timesteps"]
numeric_df = df[numeric_cols].copy()

corr = numeric_df.corr()

plt.figure(figsize=(7, 6))
sns.heatmap(corr, annot=True, fmt=".2f", cmap="coolwarm", square=True)
plt.title("Correlation Heatmap of Core Runner–IT Features")
plt.tight_layout()
plt.show()


=========================================================================================================================================================================
=========================================================================================================================================================================

from sklearn.ensemble import RandomForestClassifier

# 2.1 Build feature matrix X and target y

base_features = [
    "target_distance",
    "closing_speed",
    "heading_diff",
    "remaining_timesteps",
]

# Optional features if they exist
optional_features = []
for col in ["it_speed", "target_speed"]:
    if col in df.columns:
        optional_features.append(col)

# Pattern dummies (columns starting with 'target_pattern_')
pattern_features = [c for c in df.columns if c.startswith("target_pattern_")]

feature_cols = base_features + optional_features + pattern_features

X = df[feature_cols].copy()

# Encode outcome as 0/1
y = (df["outcome"].str.upper() == "TAGGED").astype(int)

# 2.2 Train a RandomForest for feature importance
rf = RandomForestClassifier(
    n_estimators=200,
    max_depth=None,
    random_state=42,
    n_jobs=-1,
)

rf.fit(X, y)

importances = rf.feature_importances_

feat_importance = pd.DataFrame({
    "feature": feature_cols,
    "importance": importances
}).sort_values("importance", ascending=False)

print("=== Top-5 Features by RandomForest Importance ===")
print(feat_importance.head(5))

# 2.3 Plot top-10 for a nicer view
top_n = 10
plt.figure(figsize=(8, 6))
sns.barplot(
    data=feat_importance.head(top_n),
    x="importance",
    y="feature",
    orient="h",
    palette="viridis",
)
plt.title("Top Feature Importances for Tag Prediction")
plt.xlabel("Importance")
plt.ylabel("Feature")
plt.tight_layout()
plt.show()


=========================================================================================================================================================================
=========================================================================================================================================================================

from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 (needed for 3D)
import matplotlib.pyplot as plt
import numpy as np

def plot_match_3d(df, match_id, runner_idx="target"):
    """
    3D ECEF trajectory visualization for one match.
    
    Parameters
    ----------
    df : pd.DataFrame
        Full dataset.
    match_id : hashable
        Identifier for one episode / simulation run.
    runner_idx : int or "target"
        If int, uses that runner index for the whole episode.
        If "target", uses the runner indicated by it_runner_index at each timestep.
    """
    # Filter to single match & sort by time
    match_df = df[df["match_id"] == match_id].sort_values("timestep").reset_index(drop=True)
    
    it_x, it_y, it_z = [], [], []
    r_x, r_y, r_z = [], [], []
    
    for _, row in match_df.iterrows():
        it_loc = np.array(row["it_location"])  # [x, y, z]
        it_x.append(it_loc[0])
        it_y.append(it_loc[1])
        it_z.append(it_loc[2])
        
        if runner_idx == "target":
            r_idx = int(row["it_runner_index"])
        else:
            r_idx = int(runner_idx)
        
        runner_loc = np.array(row["runners_location"][r_idx])
        r_x.append(runner_loc[0])
        r_y.append(runner_loc[1])
        r_z.append(runner_loc[2])
    
    fig = plt.figure(figsize=(10, 8))
    ax = fig.add_subplot(111, projection="3d")
    
    # Plot IT drone path
    ax.plot(it_x, it_y, it_z, label="IT Drone", color="red", linewidth=2)
    ax.scatter(it_x[0], it_y[0], it_z[0], color="darkred", marker="o", s=50, label="IT Start")
    ax.scatter(it_x[-1], it_y[-1], it_z[-1], color="pink", marker="x", s=50, label="IT End")
    
    # Plot Runner path
    ax.plot(r_x, r_y, r_z, label="Runner", color="green", linewidth=2)
    ax.scatter(r_x[0], r_y[0], r_z[0], color="darkgreen", marker="o", s=50, label="Runner Start")
    ax.scatter(r_x[-1], r_y[-1], r_z[-1], color="lightgreen", marker="x", s=50, label="Runner End")
    
    ax.set_xlabel("X (ECEF)")
    ax.set_ylabel("Y (ECEF)")
    ax.set_zlabel("Z (ECEF)")
    ax.set_title(f"3D ECEF Trajectory - Match {match_id}")
    ax.legend()
    
    # Make aspect ratio a bit nicer
    max_range = np.array([
        max(it_x + r_x) - min(it_x + r_x),
        max(it_y + r_y) - min(it_y + r_y),
        max(it_z + r_z) - min(it_z + r_z),
    ]).max() / 2.0
    
    mid_x = (max(it_x + r_x) + min(it_x + r_x)) * 0.5
    mid_y = (max(it_y + r_y) + min(it_y + r_y)) * 0.5
    mid_z = (max(it_z + r_z) + min(it_z + r_z)) * 0.5
    
    ax.set_xlim(mid_x - max_range, mid_x + max_range)
    ax.set_ylim(mid_y - max_range, mid_y + max_range)
    ax.set_zlim(mid_z - max_range, mid_z + max_range)
    
    plt.tight_layout()
    plt.show()

# Example usage (update match_id to something valid in your df):
# plot_match_3d(df, match_id=0, runner_idx="target")

=========================================================================================================================================================================
=========================================================================================================================================================================


=========================================================================================================================================================================
=========================================================================================================================================================================


=========================================================================================================================================================================
=========================================================================================================================================================================


=========================================================================================================================================================================
=========================================================================================================================================================================
Extras

- Anomaly Detection
def _render_table_and_plot(
    df: pd.DataFrame,
    PCs: np.ndarray,
    scores01: np.ndarray,
    raw_scores: np.ndarray,
    method_label: str,
    key_prefix: str,
    pca,  # global PCA (for loadings)
):
    """
    Renders three visual perspectives for a given anomaly method:

      1) Storyboard:
         - Top anomalies table with row selection
         - PCA scatter with optional highlight
         - PCA loading arrows (global + segment-anchored)
         - Segment Comparison & FR correlation
         - Per-selection 'Why this run?' bar chart

      2) Cluster Heatmap:
         - Cluster-vs-feature heatmap in z-score space

      3) Feature Network:
         - Small network of top anomaly-driving features
    """
    df = df.copy()
    df["anomaly_score"] = scores01
    df["raw_anomaly_score"] = raw_scores

    st.markdown(f"### {method_label}")

    tab_story, tab_cluster, tab_network = st.tabs(
        ["Storyboard", "Cluster Heatmap", "Feature Network"]
    )

    # === 1) STORYBOARD TAB ===
    with tab_story:
        # --- Top anomalies: select a row to highlight on the plot ---
        highlight_pos = None
        if show_top > 0:
            cols_keep = [
                "Test_Run_ID",
                "FR",
                "Num_Tests",
                "total_init_time",
                "anomaly_score",
                "raw_anomaly_score",
                "Simulation_Host",
                "Simulation_Node",
                "Capability",
                "Script_File",
                "V",
                "s_number",
                "Build",
            ]
            cols_keep = [c for c in cols_keep if c in df.columns]

            top = df.sort_values("anomaly_score", ascending=False).head(show_top)

            st.markdown("**Top anomalies**")
            editable = top[cols_keep].copy()
            editable.insert(0, "Select", False)

            edited = st.data_editor(
                editable,
                use_container_width=True,
                num_rows="fixed",
                disabled={c: True for c in editable.columns if c != "Select"},
                key=f"{key_prefix}-table",
            )

            selected_original_idxs = edited.index[edited["Select"]].tolist()
            if selected_original_idxs:
                pos = df.index.get_indexer([selected_original_idxs[0]])
                if len(pos) and pos[0] != -1:
                    highlight_pos = int(pos[0])

        # --- PCA plot with optional highlight ---
        fig = plot_for_df(df, PCs, label_choice, highlight_pos=highlight_pos)

        # === Driver arrows overlays (global + low/high FR anchors) ===
        if show_biplot and PCs.shape[1] >= 2 and pca is not None:
            # 1) Global arrows from origin
            try:
                add_pca_loadings_3d(fig, pca, PCA_FEATURES, scale=2.0)
            except Exception:
                pass

            # 2) Segment-anchored arrows near Low-FR and High-FR bands
            try:
                seg = make_fr_segments(df)  # "Low FR" / "Mid FR" / "High FR"
                # Low-FR centroid
                low_mask = (seg == "Low FR").values
                if np.any(low_mask):
                    low_anchor = PCs[low_mask].mean(axis=0)
                    add_biplot_arrows_at_anchor_3d(
                        fig,
                        pca,
                        PCA_FEATURES,
                        low_anchor,
                        scale=1.2,
                        color="green",
                        name_prefix="Low FR ",
                        showlegend=False,
                    )
                # High-FR centroid
                high_mask = (seg == "High FR").values
                if np.any(high_mask):
                    high_anchor = PCs[high_mask].mean(axis=0)
                    add_biplot_arrows_at_anchor_3d(
                        fig,
                        pca,
                        PCA_FEATURES,
                        high_anchor,
                        scale=1.2,
                        color="red",
                        name_prefix="High FR ",
                        showlegend=False,
                    )
            except Exception:
                pass

        st.plotly_chart(fig, use_container_width=True, key=f"{key_prefix}-plot")

        # --- Segment Comparison + FR Correlation ---
        if show_segment_compare:
            c1, c2 = st.columns([2, 1])
            with c1:
                st.markdown("#### Segment Comparison: Low vs High FR")
                st.plotly_chart(
                    segment_diff_bar(df),
                    use_container_width=True,
                    key=f"{key_prefix}-segdiff",
                )
            with c2:
                st.markdown("#### FR Correlation")
                st.plotly_chart(
                    fr_correlation_heatmap(df),
                    use_container_width=True,
                    key=f"{key_prefix}-frcorr",
                )

        # --- Per-selection “Why this run?” ---
        if show_selection_why and highlight_pos is not None:
            st.markdown("#### Why this run?")
            st.plotly_chart(
                per_point_contribution_bar(df, highlight_pos),
                use_container_width=True,
                key=f"{key_prefix}-whybar",
            )

    # === 2) CLUSTER HEATMAP TAB ===
    with tab_cluster:
        st.markdown("#### Cluster-level feature patterns")
        st.plotly_chart(
            cluster_profile_heatmap(df, PCs, scores01),
            use_container_width=True,
            key=f"{key_prefix}-clusterheat",
        )

    # === 3) FEATURE NETWORK TAB ===
    with tab_network:
        # Use the most anomalous subset to focus the network
        n_sub = max(20, int(0.2 * len(df)))
        df_anom = df.sort_values("anomaly_score", ascending=False).head(n_sub)
        st.markdown("#### Relationships among top anomaly-driving features")
        st.plotly_chart(
            feature_influence_network_figure(df_anom),
            use_container_width=True,
            key=f"{key_prefix}-featnet",
        )


